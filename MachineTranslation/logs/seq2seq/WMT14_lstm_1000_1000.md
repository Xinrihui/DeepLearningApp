## 1.基本参数

### 1.1 数据集参数
    
    WMT14 English-Germa 数据集 
    
    (预处理后的 数据集地址 https://nlp.stanford.edu/projects/nmt/ )

### 1.2 模型参数
    
    基于词粒度(word level)
    
    词向量维度 n_embedding = 1000
    
    隐藏层的维度 n_h = 1000

## 2.实验记录

### 2.1 验证 多层堆叠 LSTM 的效果

#### 实验 1 单层 LSTM 
    
    (0) 模型
       
       编码器和解码器均为单层 LSTM, 解码器的 LSTM 和 输出层 中间使用 Dropout 连接, 参数 dropout_rates = (0.2,)
    
    (1) 数据集 
    
    训练数据:   
    N_train = 4094299 ( 源句子-目标句子对 的数目, 过滤掉长度大于 50)
    
    source sentence length distribution:
    most common seq length: (seq length, count num)
    [(17, 155827), (16, 155629), (15, 154656), (18, 153586), (19, 151796), (14, 149838), (20, 147657), (13, 143601), (21, 143144), (22, 139581)]
    seq length count:  (seq length, count num)
    [(100, 572), (99, 616), (98, 645), (97, 711), (96, 782), (95, 829), (94, 859), (93, 1004), (92, 1022), (91, 1117), (90, 1271), (89, 1305), (88, 1543), (87, 1572), (86, 1629), (85, 1698), (84, 1904), (83, 1976), (82, 2154), (81, 2365), (80, 2506), (79, 2846), (78, 3033), (77, 3184), (76, 3518), (75, 3630), (74, 4014), (73, 4170), (72, 4749), (71, 5061), (70, 5388), (69, 5590), (68, 6176), (67, 6689), (66, 7217), (65, 7744), (64, 8343), (63, 9033), (62, 9905), (61, 10646), (60, 11308), (59, 12336), (58, 13193), (57, 14414), (56, 15450), (55, 16969), (54, 18876), (53, 20326), (52, 20903), (51, 22590), (50, 24098), (49, 25983), (48, 28325), (47, 30461), (46, 32027), (45, 35146), (44, 37382), (43, 40306), (42, 43267), (41, 46180), (40, 50308), (39, 53441), (38, 57900), (37, 62886), (36, 66840), (35, 71266), (34, 76766), (33, 81583), (32, 87484), (31, 92126), (30, 97864), (29, 102435), (28, 107874), (27, 113869), (26, 119401), (25, 124660), (24, 130374), (23, 135714), (22, 139581), (21, 143144), (20, 147657), (19, 151796), (18, 153586), (17, 155827), (16, 155629), (15, 154656), (14, 149838), (13, 143601), (12, 138078), (11, 128739), (10, 114370), (9, 102814), (8, 79692), (7, 59132), (6, 26251), (5, 19701), (4, 8034), (3, 6680), (2, 2357), (1, 6330)]
    
    target sentence length distribution:
    most common seq length: (seq length, count num)
    [(16, 165532), (15, 164658), (14, 162805), (17, 162654), (18, 159080), (13, 156485), (19, 155026), (20, 152030), (12, 150160), (21, 146299)]
    seq length count:  (seq length, count num)
    [(100, 296), (99, 305), (98, 337), (97, 404), (96, 408), (95, 505), (94, 531), (93, 592), (92, 625), (91, 679), (90, 780), (89, 823), (88, 946), (87, 1030), (86, 1043), (85, 1231), (84, 1310), (83, 1419), (82, 1578), (81, 1669), (80, 1809), (79, 2021), (78, 2093), (77, 2262), (76, 2526), (75, 2686), (74, 2929), (73, 3126), (72, 3490), (71, 3657), (70, 4098), (69, 4449), (68, 4756), (67, 5061), (66, 5529), (65, 6028), (64, 6545), (63, 7198), (62, 7723), (61, 8621), (60, 9866), (59, 10771), (58, 11773), (57, 11776), (56, 12672), (55, 13951), (54, 15069), (53, 15959), (52, 17481), (51, 18943), (50, 20747), (49, 22558), (48, 24116), (47, 26549), (46, 28347), (45, 30953), (44, 33673), (43, 35959), (42, 38732), (41, 41909), (40, 46090), (39, 49991), (38, 53894), (37, 56454), (36, 60835), (35, 65440), (34, 70125), (33, 75182), (32, 81015), (31, 86883), (30, 91586), (29, 98251), (28, 104117), (27, 111076), (26, 118207), (25, 123028), (24, 128857), (23, 134906), (22, 140894), (21, 146299), (20, 152030), (19, 155026), (18, 159080), (17, 162654), (16, 165532), (15, 164658), (14, 162805), (13, 156485), (12, 150160), (11, 142053), (10, 134701), (9, 123547), (8, 97630), (7, 74183), (6, 33878), (5, 21733), (4, 8039), (3, 9064), (2, 2468), (1, 5062)]
    
    seq length <=50 num: 4094299
    
    验证数据: newstest2013 
    N_valid = 2883  (过滤掉长度大于 50)
    
    source sentence length distribution:
    most common seq length: (seq length, count num)
    [(20, 121), (13, 120), (14, 115), (15, 115), (16, 115), (11, 108), (19, 106), (21, 103), (18, 103), (17, 103)]
    seq length count:  (seq length, count num)
    [(106, 1), (92, 1), (91, 1), (90, 1), (88, 1), (86, 1), (80, 2), (79, 1), (78, 1), (76, 1), (75, 1), (74, 2), (72, 1), (70, 2), (68, 1), (66, 2), (64, 3), (63, 4), (62, 6), (61, 2), (60, 4), (59, 5), (58, 4), (57, 3), (56, 3), (55, 6), (54, 9), (53, 13), (52, 8), (51, 12), (50, 10), (49, 14), (48, 17), (47, 10), (46, 14), (45, 15), (44, 10), (43, 16), (42, 13), (41, 19), (40, 33), (39, 22), (38, 24), (37, 27), (36, 40), (35, 34), (34, 45), (33, 61), (32, 45), (31, 49), (30, 53), (29, 65), (28, 58), (27, 69), (26, 79), (25, 73), (24, 81), (23, 88), (22, 98), (21, 103), (20, 121), (19, 106), (18, 103), (17, 103), (16, 115), (15, 115), (14, 115), (13, 120), (12, 96), (11, 108), (10, 98), (9, 89), (8, 89), (7, 68), (6, 67), (5, 37), (4, 24), (3, 14), (2, 18), (1, 7)]
    
    target sentence length distribution:
    most common seq length: (seq length, count num)
    [(13, 129), (15, 122), (16, 117), (11, 115), (12, 111), (20, 108), (14, 107), (10, 106), (19, 105), (18, 104)]
    seq length count:  (seq length, count num)
    [(103, 1), (98, 1), (95, 2), (92, 1), (87, 1), (85, 1), (84, 1), (83, 1), (81, 1), (80, 1), (79, 1), (77, 1), (74, 1), (72, 1), (71, 1), (69, 3), (67, 2), (66, 2), (64, 2), (63, 5), (62, 3), (61, 3), (60, 3), (59, 3), (58, 4), (57, 8), (56, 3), (55, 4), (54, 5), (53, 7), (52, 7), (51, 13), (50, 4), (49, 7), (48, 9), (47, 9), (46, 16), (45, 20), (44, 12), (43, 16), (42, 21), (41, 26), (40, 30), (39, 30), (38, 25), (37, 29), (36, 32), (35, 38), (34, 34), (33, 53), (32, 37), (31, 54), (30, 62), (29, 61), (28, 77), (27, 67), (26, 62), (25, 64), (24, 94), (23, 78), (22, 80), (21, 89), (20, 108), (19, 105), (18, 104), (17, 97), (16, 117), (15, 122), (14, 107), (13, 129), (12, 111), (11, 115), (10, 106), (9, 93), (8, 80), (7, 95), (6, 64), (5, 54), (4, 21), (3, 19), (2, 17), (1, 7)]

    
    测试数据: newstest2014
    N_test = 2737 
    
    source sentence length distribution:
    most common seq length: (seq length, count num)
    [(13, 113), (14, 112), (18, 112), (16, 101), (17, 100), (15, 100), (20, 95), (19, 94), (23, 94), (21, 92)]
    seq length count:  (seq length, count num)
    [(91, 1), (83, 1), (79, 1), (72, 2), (69, 1), (68, 2), (64, 2), (63, 2), (62, 1), (61, 2), (59, 2), (58, 9), (57, 2), (56, 4), (55, 7), (54, 2), (53, 4), (52, 7), (51, 11), (50, 14), (49, 8), (48, 12), (47, 14), (46, 15), (45, 15), (44, 26), (43, 29), (42, 21), (41, 14), (40, 29), (39, 33), (38, 35), (37, 35), (36, 44), (35, 41), (34, 46), (33, 47), (32, 53), (31, 66), (30, 63), (29, 59), (28, 73), (27, 77), (26, 58), (25, 85), (24, 86), (23, 94), (22, 92), (21, 92), (20, 95), (19, 94), (18, 112), (17, 100), (16, 101), (15, 100), (14, 112), (13, 113), (12, 82), (11, 81), (10, 73), (9, 69), (8, 52), (7, 50), (6, 36), (5, 15), (4, 7), (3, 4), (2, 2)]
    
    target sentence length distribution:
    most common seq length: (seq length, count num)
    [(19, 125), (14, 119), (15, 118), (13, 105), (17, 105), (12, 103), (10, 101), (16, 100), (20, 98), (21, 96)]
    seq length count:  (seq length, count num)
    [(75, 1), (72, 2), (70, 1), (68, 1), (64, 1), (63, 2), (60, 3), (59, 3), (58, 1), (57, 3), (56, 5), (55, 3), (54, 2), (53, 9), (52, 7), (51, 2), (50, 8), (49, 7), (48, 12), (47, 11), (46, 14), (45, 20), (44, 15), (43, 17), (42, 25), (41, 19), (40, 28), (39, 23), (38, 19), (37, 27), (36, 32), (35, 43), (34, 37), (33, 41), (32, 58), (31, 48), (30, 67), (29, 56), (28, 66), (27, 63), (26, 71), (25, 71), (24, 64), (23, 89), (22, 84), (21, 96), (20, 98), (19, 125), (18, 79), (17, 105), (16, 100), (15, 118), (14, 119), (13, 105), (12, 103), (11, 92), (10, 101), (9, 87), (8, 60), (7, 73), (6, 46), (5, 28), (4, 14), (3, 6), (2, 1)]

    
    (2) 数据预处理
    
    对英语和德语都做 unicode 标准化(NKFC), 并进行大小写折叠(case fold)
    
    删除语料库中不在拉丁语系中的单词, 单独出现的数字, 符号( 保留 ' 和 - ), 和特殊的无意义单词: ##AT##-##AT## , &apos , &quot,
    
    源语言词表大小: n_vocab_source=50k
    目标语言词表大小: n_vocab_target=50k
    
    对于训练数据和验证数据, 将句子向量化为固定的长度
    源句子向量化后的长度: max_seq_length = 50
    目标句子向量化后的长度: max_seq_length = 50
    
    将源句子反向输入模型
    
    (3) 优化器参数
    
    epoch_num = 10
    batch_size = 256
    optimizer='rmsprop'
    
    
    (5) 训练过程
    
    在每一个 epoch 结束时都对模型进行持久化(checkpoint), 并计算在验证集上的 bleu 得分
    
    Epoch 1/10
    bleu_score:{'1-garm': 0.26906431123853325, '2-garm': 0.13892282776175313, '3-garm': 0.07750465817155257, '4-garm': 0.04502927217545498}
    15994/15994 [==============================] - 4177s 261ms/step - loss: 1.7699 - accuracy: 0.7322 - val_loss: 1.5427 - val_accuracy: 0.7691
    
    Epoch 2/10
    bleu_score:{'1-garm': 0.28767879752889564, '2-garm': 0.15318258926037973, '3-garm': 0.0872974024872314, '4-garm': 0.05174735788535346}
    15994/15994 [==============================] - 4213s 263ms/step - loss: 1.6417 - accuracy: 0.7497 - val_loss: 1.5186 - val_accuracy: 0.7745
    
    Epoch 3/10
    bleu_score:{'1-garm': 0.29327253561534095, '2-garm': 0.1585406957637988, '3-garm': 0.09154815258911893, '4-garm': 0.05465899343131736}
    15994/15994 [==============================] - 4206s 263ms/step - loss: 1.6287 - accuracy: 0.7533 - val_loss: 1.5134 - val_accuracy: 0.7764
    
    Epoch 4/10
    bleu_score:{'1-garm': 0.3037168617589985, '2-garm': 0.16600837433151827, '3-garm': 0.09747612465811514, '4-garm': 0.059048954203868735}
    15994/15994 [==============================] - 4232s 264ms/step - loss: 1.6168 - accuracy: 0.7552 - val_loss: 1.5102 - val_accuracy: 0.7788
    
    Epoch 5/10
    bleu_score:{'1-garm': 0.3065308686010539, '2-garm': 0.16739763314001765, '3-garm': 0.09773008500932075, '4-garm': 0.05905037184741836}
    15994/15994 [==============================] - 4230s 264ms/step - loss: 1.6036 - accuracy: 0.7559 - val_loss: 1.5005 - val_accuracy: 0.7781
    
    Epoch 6/10
    bleu_score:{'1-garm': 0.30456168027873015, '2-garm': 0.16686701810797228, '3-garm': 0.09811753364093108, '4-garm': 0.06000295699560698}
    15994/15994 [==============================] - 4191s 262ms/step - loss: 1.6003 - accuracy: 0.7564 - val_loss: 1.4986 - val_accuracy: 0.7788
    
    Epoch 7/10
    bleu_score:{'1-garm': 0.31459447407842933, '2-garm': 0.17150909764536945, '3-garm': 0.1011506926773095, '4-garm': 0.06121008146521982}
    15994/15994 [==============================] - 4177s 261ms/step - loss: 1.5901 - accuracy: 0.7570 - val_loss: 1.4922 - val_accuracy: 0.7792
    
    Epoch 8/10
    bleu_score:{'1-garm': 0.3025677391608834, '2-garm': 0.1680371744934818, '3-garm': 0.10001539903710409, '4-garm': 0.060889438998815465}
    15994/15994 [==============================] - 4180s 261ms/step - loss: 1.5781 - accuracy: 0.7575 - val_loss: 1.4919 - val_accuracy: 0.7781
    
    Epoch 9/10
    bleu_score:{'1-garm': 0.31067212184425474, '2-garm': 0.16976806710631545, '3-garm': 0.09906530592113495, '4-garm': 0.05991219079175276}
    15994/15994 [==============================] - 4212s 263ms/step - loss: 1.5704 - accuracy: 0.7575 - val_loss: 1.4955 - val_accuracy: 0.7785
    
    Epoch 10/10
    bleu_score:{'1-garm': 0.30286884248296114, '2-garm': 0.1664034218930476, '3-garm': 0.09851564837247777, '4-garm': 0.06057840910264559}
    15994/15994 [==============================] - 4236s 264ms/step - loss: 1.5645 - accuracy: 0.7580 - val_loss: 1.4897 - val_accuracy: 0.7786
    
    final learning_rate: 0.001

        
    (6) 模型评价
    
    1.epoch=7 时的模型
    
    保留所有的 [UNK] 进行评价
    
    candidates:
    [0] orlando die [UNK] und die [UNK] frau miranda sind immer noch [UNK] [END]
    [1] [UNK] demokratien und andere [UNK] [UNK] ihre [UNK] wollen sich verschiedene formen der [UNK] entwickeln [END]
    [2] in einem interview sagte er allerdings noch die [UNK] und die liebe [END]
    [3] in [UNK] [UNK] und [UNK] sind herrn flynn zu einem alten [UNK] [END]
    [4] die [UNK] [UNK] von frau [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [END]
    [5] in einem interview mit dem [UNK] [UNK] der [UNK] [UNK] der [UNK] [UNK] wird das [UNK] [UNK] [UNK] und wir hoffen nicht nur [UNK] sondern auch [UNK] [END]
    [6] er und das frau noch einmal liebe das jahr das [UNK] [END]
    [7] wir werden uns gegenseitig unterstützen und die eltern in [UNK] zu unterstützen [END]
    [8] die [UNK] und die [UNK] [UNK] sind seit ihrer [UNK] im leben [END]
    [9] [UNK] [UNK] [UNK] mit [UNK] [UNK] [END]
    
    references:
    [0] ['[START] orlando bloom und miranda kerr lieben sich noch immer [END]']
    [1] ['[START] schauspieler orlando bloom und model miranda kerr wollen künftig getrennte wege gehen [END]']
    [2] ['[START] in einem interview sagte bloom jedoch   dass er und kerr sich noch immer lieben [END]']
    [3] ['[START] miranda kerr und orlando bloom sind eltern des zweijährigen flynn [END]']
    [4] ['[START] schauspieler orlando bloom hat sich zur trennung von seiner frau   topmodel miranda kerr   geäussert [END]']
    [5] ['[START] in einem interview mit us  journalistin katie couric   das am freitag   ortszeit   ausgestrahlt werden sollte   sagte bloom     das leben verläuft manchmal nicht genau so   wie wir es planen oder erhoffen [END]']
    [6] ['[START] kerr und er selbst liebten sich noch immer   betonte der jährige [END]']
    [7] ['[START] wir werden uns gegenseitig unterstützen und lieben als eltern von flynn [END]']
    [8] ['[START] kerr und bloom sind seitverheiratet   im jahrwurde ihr söhnchen flynn geboren [END]']
    [9] ['[START] jumbo  hersteller streiten im angesicht grosser bestellungen über sitzbreite [END]']
    
    bleu_score:{'1-garm': 0.26551940908376553, '2-garm': 0.13258414151053394, '3-garm': 0.07172948916267198, '4-garm': 0.040995593917398473}

    
#### 实验 2 多层 LSTM 
    
    (0) 模型
       
       编码器和解码器均为 4层 LSTM, 中间使用 Dropout 连接, 一共4层 Dropout 参数 dropout_rates = (0.2, 0.2, 0.2, 0.2)
    
    (1) 数据集 
    
    训练数据:   
    N_train = 4094299 ( 源句子-目标句子对 的数目, 过滤掉长度大于 50)
    
    source sentence length distribution:
    most common seq length: (seq length, count num)
    [(17, 155827), (16, 155629), (15, 154656), (18, 153586), (19, 151796), (14, 149838), (20, 147657), (13, 143601), (21, 143144), (22, 139581)]
    seq length count:  (seq length, count num)
    [(100, 572), (99, 616), (98, 645), (97, 711), (96, 782), (95, 829), (94, 859), (93, 1004), (92, 1022), (91, 1117), (90, 1271), (89, 1305), (88, 1543), (87, 1572), (86, 1629), (85, 1698), (84, 1904), (83, 1976), (82, 2154), (81, 2365), (80, 2506), (79, 2846), (78, 3033), (77, 3184), (76, 3518), (75, 3630), (74, 4014), (73, 4170), (72, 4749), (71, 5061), (70, 5388), (69, 5590), (68, 6176), (67, 6689), (66, 7217), (65, 7744), (64, 8343), (63, 9033), (62, 9905), (61, 10646), (60, 11308), (59, 12336), (58, 13193), (57, 14414), (56, 15450), (55, 16969), (54, 18876), (53, 20326), (52, 20903), (51, 22590), (50, 24098), (49, 25983), (48, 28325), (47, 30461), (46, 32027), (45, 35146), (44, 37382), (43, 40306), (42, 43267), (41, 46180), (40, 50308), (39, 53441), (38, 57900), (37, 62886), (36, 66840), (35, 71266), (34, 76766), (33, 81583), (32, 87484), (31, 92126), (30, 97864), (29, 102435), (28, 107874), (27, 113869), (26, 119401), (25, 124660), (24, 130374), (23, 135714), (22, 139581), (21, 143144), (20, 147657), (19, 151796), (18, 153586), (17, 155827), (16, 155629), (15, 154656), (14, 149838), (13, 143601), (12, 138078), (11, 128739), (10, 114370), (9, 102814), (8, 79692), (7, 59132), (6, 26251), (5, 19701), (4, 8034), (3, 6680), (2, 2357), (1, 6330)]
    
    target sentence length distribution:
    most common seq length: (seq length, count num)
    [(16, 165532), (15, 164658), (14, 162805), (17, 162654), (18, 159080), (13, 156485), (19, 155026), (20, 152030), (12, 150160), (21, 146299)]
    seq length count:  (seq length, count num)
    [(100, 296), (99, 305), (98, 337), (97, 404), (96, 408), (95, 505), (94, 531), (93, 592), (92, 625), (91, 679), (90, 780), (89, 823), (88, 946), (87, 1030), (86, 1043), (85, 1231), (84, 1310), (83, 1419), (82, 1578), (81, 1669), (80, 1809), (79, 2021), (78, 2093), (77, 2262), (76, 2526), (75, 2686), (74, 2929), (73, 3126), (72, 3490), (71, 3657), (70, 4098), (69, 4449), (68, 4756), (67, 5061), (66, 5529), (65, 6028), (64, 6545), (63, 7198), (62, 7723), (61, 8621), (60, 9866), (59, 10771), (58, 11773), (57, 11776), (56, 12672), (55, 13951), (54, 15069), (53, 15959), (52, 17481), (51, 18943), (50, 20747), (49, 22558), (48, 24116), (47, 26549), (46, 28347), (45, 30953), (44, 33673), (43, 35959), (42, 38732), (41, 41909), (40, 46090), (39, 49991), (38, 53894), (37, 56454), (36, 60835), (35, 65440), (34, 70125), (33, 75182), (32, 81015), (31, 86883), (30, 91586), (29, 98251), (28, 104117), (27, 111076), (26, 118207), (25, 123028), (24, 128857), (23, 134906), (22, 140894), (21, 146299), (20, 152030), (19, 155026), (18, 159080), (17, 162654), (16, 165532), (15, 164658), (14, 162805), (13, 156485), (12, 150160), (11, 142053), (10, 134701), (9, 123547), (8, 97630), (7, 74183), (6, 33878), (5, 21733), (4, 8039), (3, 9064), (2, 2468), (1, 5062)]
    
    seq length <=50 num: 4094299
    
    验证数据: newstest2013 
    N_valid = 2883  (过滤掉长度大于 50)
    
    source sentence length distribution:
    most common seq length: (seq length, count num)
    [(20, 121), (13, 120), (14, 115), (15, 115), (16, 115), (11, 108), (19, 106), (21, 103), (18, 103), (17, 103)]
    seq length count:  (seq length, count num)
    [(106, 1), (92, 1), (91, 1), (90, 1), (88, 1), (86, 1), (80, 2), (79, 1), (78, 1), (76, 1), (75, 1), (74, 2), (72, 1), (70, 2), (68, 1), (66, 2), (64, 3), (63, 4), (62, 6), (61, 2), (60, 4), (59, 5), (58, 4), (57, 3), (56, 3), (55, 6), (54, 9), (53, 13), (52, 8), (51, 12), (50, 10), (49, 14), (48, 17), (47, 10), (46, 14), (45, 15), (44, 10), (43, 16), (42, 13), (41, 19), (40, 33), (39, 22), (38, 24), (37, 27), (36, 40), (35, 34), (34, 45), (33, 61), (32, 45), (31, 49), (30, 53), (29, 65), (28, 58), (27, 69), (26, 79), (25, 73), (24, 81), (23, 88), (22, 98), (21, 103), (20, 121), (19, 106), (18, 103), (17, 103), (16, 115), (15, 115), (14, 115), (13, 120), (12, 96), (11, 108), (10, 98), (9, 89), (8, 89), (7, 68), (6, 67), (5, 37), (4, 24), (3, 14), (2, 18), (1, 7)]
    
    target sentence length distribution:
    most common seq length: (seq length, count num)
    [(13, 129), (15, 122), (16, 117), (11, 115), (12, 111), (20, 108), (14, 107), (10, 106), (19, 105), (18, 104)]
    seq length count:  (seq length, count num)
    [(103, 1), (98, 1), (95, 2), (92, 1), (87, 1), (85, 1), (84, 1), (83, 1), (81, 1), (80, 1), (79, 1), (77, 1), (74, 1), (72, 1), (71, 1), (69, 3), (67, 2), (66, 2), (64, 2), (63, 5), (62, 3), (61, 3), (60, 3), (59, 3), (58, 4), (57, 8), (56, 3), (55, 4), (54, 5), (53, 7), (52, 7), (51, 13), (50, 4), (49, 7), (48, 9), (47, 9), (46, 16), (45, 20), (44, 12), (43, 16), (42, 21), (41, 26), (40, 30), (39, 30), (38, 25), (37, 29), (36, 32), (35, 38), (34, 34), (33, 53), (32, 37), (31, 54), (30, 62), (29, 61), (28, 77), (27, 67), (26, 62), (25, 64), (24, 94), (23, 78), (22, 80), (21, 89), (20, 108), (19, 105), (18, 104), (17, 97), (16, 117), (15, 122), (14, 107), (13, 129), (12, 111), (11, 115), (10, 106), (9, 93), (8, 80), (7, 95), (6, 64), (5, 54), (4, 21), (3, 19), (2, 17), (1, 7)]

    
    测试数据: newstest2014
    N_test = 2737 
    
    source sentence length distribution:
    most common seq length: (seq length, count num)
    [(13, 113), (14, 112), (18, 112), (16, 101), (17, 100), (15, 100), (20, 95), (19, 94), (23, 94), (21, 92)]
    seq length count:  (seq length, count num)
    [(91, 1), (83, 1), (79, 1), (72, 2), (69, 1), (68, 2), (64, 2), (63, 2), (62, 1), (61, 2), (59, 2), (58, 9), (57, 2), (56, 4), (55, 7), (54, 2), (53, 4), (52, 7), (51, 11), (50, 14), (49, 8), (48, 12), (47, 14), (46, 15), (45, 15), (44, 26), (43, 29), (42, 21), (41, 14), (40, 29), (39, 33), (38, 35), (37, 35), (36, 44), (35, 41), (34, 46), (33, 47), (32, 53), (31, 66), (30, 63), (29, 59), (28, 73), (27, 77), (26, 58), (25, 85), (24, 86), (23, 94), (22, 92), (21, 92), (20, 95), (19, 94), (18, 112), (17, 100), (16, 101), (15, 100), (14, 112), (13, 113), (12, 82), (11, 81), (10, 73), (9, 69), (8, 52), (7, 50), (6, 36), (5, 15), (4, 7), (3, 4), (2, 2)]
    
    target sentence length distribution:
    most common seq length: (seq length, count num)
    [(19, 125), (14, 119), (15, 118), (13, 105), (17, 105), (12, 103), (10, 101), (16, 100), (20, 98), (21, 96)]
    seq length count:  (seq length, count num)
    [(75, 1), (72, 2), (70, 1), (68, 1), (64, 1), (63, 2), (60, 3), (59, 3), (58, 1), (57, 3), (56, 5), (55, 3), (54, 2), (53, 9), (52, 7), (51, 2), (50, 8), (49, 7), (48, 12), (47, 11), (46, 14), (45, 20), (44, 15), (43, 17), (42, 25), (41, 19), (40, 28), (39, 23), (38, 19), (37, 27), (36, 32), (35, 43), (34, 37), (33, 41), (32, 58), (31, 48), (30, 67), (29, 56), (28, 66), (27, 63), (26, 71), (25, 71), (24, 64), (23, 89), (22, 84), (21, 96), (20, 98), (19, 125), (18, 79), (17, 105), (16, 100), (15, 118), (14, 119), (13, 105), (12, 103), (11, 92), (10, 101), (9, 87), (8, 60), (7, 73), (6, 46), (5, 28), (4, 14), (3, 6), (2, 1)]

    
    (2) 数据预处理
    
    对英语和德语都做 unicode 标准化(NKFC), 并进行大小写折叠(case fold)
    
    删除语料库中不在拉丁语系中的单词, 单独出现的数字, 符号( 保留 ' 和 - ), 和特殊的无意义单词: ##AT##-##AT## , &apos , &quot,
    
    源语言词表大小: n_vocab_source=50k
    目标语言词表大小: n_vocab_target=50k
    
    对于训练数据和验证数据, 将句子向量化为固定的长度
    源句子向量化后的长度: max_seq_length = 50
    目标句子向量化后的长度: max_seq_length = 50
    
    将源句子反向输入模型
    
    (3) 优化器参数
    
    epoch_num = 12
    batch_size = 256
    optimizer='rmsprop'
    
    
    (5) 训练过程
    
    在每一个 epoch 结束时都对模型进行持久化(checkpoint), 并计算在验证集上的 bleu 得分
    
    Epoch 1/12
    bleu_score:{'1-garm': 0.2927807808024845, '2-garm': 0.15802095594052679, '3-garm': 0.0908199575811617, '4-garm': 0.053555580289051684}
    15994/15994 [==============================] - 6743s 421ms/step - loss: 1.8071 - accuracy: 0.7269 - val_loss: 1.4778 - val_accuracy: 0.7776
    
    Epoch 2/12
    bleu_score:{'1-garm': 0.32945003931848743, '2-garm': 0.18717898569905891, '3-garm': 0.1124299499446621, '4-garm': 0.06880521871527136}
    15994/15994 [==============================] - 6748s 422ms/step - loss: 1.5728 - accuracy: 0.7586 - val_loss: 1.3891 - val_accuracy: 0.7910
    
    Epoch 3/12
    bleu_score:{'1-garm': 0.34194509998757916, '2-garm': 0.19939824027323835, '3-garm': 0.12294136657620831, '4-garm': 0.07754104611570223}
    15994/15994 [==============================] - 6717s 420ms/step - loss: 1.5102 - accuracy: 0.7675 - val_loss: 1.3358 - val_accuracy: 0.7971
    
    Epoch 4/12
    bleu_score:{'1-garm': 0.3573127745104812, '2-garm': 0.21329785785868838, '3-garm': 0.13495926946239886, '4-garm': 0.08774796626423927}
    15994/15994 [==============================] - 6728s 420ms/step - loss: 1.4680 - accuracy: 0.7722 - val_loss: 1.2967 - val_accuracy: 0.8005
    
    Epoch 5/12
    bleu_score:{'1-garm': 0.3628503254367415, '2-garm': 0.22042410875287544, '3-garm': 0.14147943083002182, '4-garm': 0.09285215099740472}
    15994/15994 [==============================] - 6718s 420ms/step - loss: 1.4309 - accuracy: 0.7751 - val_loss: 1.2613 - val_accuracy: 0.8026
    
    Epoch 6/12
    bleu_score:{'1-garm': 0.366310568385136, '2-garm': 0.2215520397507127, '3-garm': 0.14197023323882105, '4-garm': 0.09298920693896214}
    15994/15994 [==============================] - 6703s 419ms/step - loss: 1.4015 - accuracy: 0.7772 - val_loss: 1.2442 - val_accuracy: 0.8046
    
    Epoch 7/12
    bleu_score:{'1-garm': 0.36581696667794594, '2-garm': 0.2232961211017132, '3-garm': 0.14504849050205348, '4-garm': 0.09610680536555713}
    15994/15994 [==============================] - 6664s 416ms/step - loss: 1.3778 - accuracy: 0.7790 - val_loss: 1.2271 - val_accuracy: 0.8047
    
    Epoch 8/12
    bleu_score:{'1-garm': 0.3731345741239408, '2-garm': 0.22866357009685678, '3-garm': 0.14854732658342437, '4-garm': 0.09852933296218408}
    15994/15994 [==============================] - 6653s 416ms/step - loss: 1.3614 - accuracy: 0.7804 - val_loss: 1.2095 - val_accuracy: 0.8066
    
    Epoch 9/12
    bleu_score:{'1-garm': 0.3737876538367328, '2-garm': 0.231461950111023, '3-garm': 0.15175466044040636, '4-garm': 0.10175978268678328}
    15994/15994 [==============================] - 6646s 415ms/step - loss: 1.3448 - accuracy: 0.7818 - val_loss: 1.2018 - val_accuracy: 0.8072
    
    Epoch 10/12
    bleu_score:{'1-garm': 0.3781398226160201, '2-garm': 0.23408490626436834, '3-garm': 0.1524580594065548, '4-garm': 0.10087917334905275}
    15994/15994 [==============================] - 6644s 415ms/step - loss: 1.3341 - accuracy: 0.7828 - val_loss: 1.1951 - val_accuracy: 0.8076
    
    Epoch 11/12
    bleu_score:{'1-garm': 0.3771924143490509, '2-garm': 0.23538115209085914, '3-garm': 0.15431791246725446, '4-garm': 0.1028163755767715}
    15994/15994 [==============================] - 6679s 417ms/step - loss: 1.3240 - accuracy: 0.7839 - val_loss: 1.2007 - val_accuracy: 0.8080
    
    Epoch 12/12
    bleu_score:{'1-garm': 0.38525159112998125, '2-garm': 0.23990009765492076, '3-garm': 0.15779280439449425, '4-garm': 0.10602667375440637}
    15994/15994 [==============================] - 6674s 417ms/step - loss: 1.3175 - accuracy: 0.7848 - val_loss: 1.1933 - val_accuracy: 0.8089
    
    (6) 模型评价
    
    1.epoch=12 时的模型
    
    保留所有的 [UNK] 进行评价
    
    candidates:
    [0] orlando palme und lady thomsen lieben sich immer noch [END]
    [1] akteure orlando hillary und ihr modell brown [UNK] wollen sich voneinander trennen [END]
    [2] in einem interview sagte er aber dass koizumi und sarkozys sich immer noch lieben [END]
    [3] brown [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]
    [4] der schauspieler orlando [UNK] kündigte seine frau [UNK] brown watts an [END]
    [5] in einem interview mit dem us journalisten [UNK] [UNK] der am freitag den [UNK] wird ist das leben manchmal nicht so wie wir es wünschen oder planen [END]
    [6] er und sarkozys haben sich immer noch das alte jahr [UNK] [END]
    [7] wir werden uns gegenseitig und einander als eltern unterstützen [END]
    [8] die familie ist geboren und geboren seit dem [UNK] [UNK] [UNK] [END]
    [9] die [UNK] [UNK] über grosse [UNK] auf dem spiel [END]
    
    references:
    [0] ['[START] orlando bloom und miranda kerr lieben sich noch immer [END]']
    [1] ['[START] schauspieler orlando bloom und model miranda kerr wollen künftig getrennte wege gehen [END]']
    [2] ['[START] in einem interview sagte bloom jedoch   dass er und kerr sich noch immer lieben [END]']
    [3] ['[START] miranda kerr und orlando bloom sind eltern des zweijährigen flynn [END]']
    [4] ['[START] schauspieler orlando bloom hat sich zur trennung von seiner frau   topmodel miranda kerr   geäussert [END]']
    [5] ['[START] in einem interview mit us  journalistin katie couric   das am freitag   ortszeit   ausgestrahlt werden sollte   sagte bloom     das leben verläuft manchmal nicht genau so   wie wir es planen oder erhoffen [END]']
    [6] ['[START] kerr und er selbst liebten sich noch immer   betonte der jährige [END]']
    [7] ['[START] wir werden uns gegenseitig unterstützen und lieben als eltern von flynn [END]']
    [8] ['[START] kerr und bloom sind seitverheiratet   im jahrwurde ihr söhnchen flynn geboren [END]']
    [9] ['[START] jumbo  hersteller streiten im angesicht grosser bestellungen über sitzbreite [END]']
    
    bleu_score:{'1-garm': 0.31899971256108073, '2-garm': 0.18726289018404474, '3-garm': 0.11706067030795403, '4-garm': 0.07583102173005586}



### 2.2 验证 数据预处理的效果

#### 实验 3 不做数据预处理
    
    (0) 模型
       
       编码器和解码器均为 4层 LSTM, 中间使用 Dropout 连接, 一共5层 Dropout 参数 dropout_rates = (0.2, 0.2, 0.2, 0.2, 0.2)
    
    (1) 数据集 
    
    训练数据:   
    N_train = 4094299 ( 源句子-目标句子对 的数目, 过滤掉长度大于 50 的序列)
    
    source sentence length distribution:
    most common seq length: (seq length, count num)
    [(17, 155827), (16, 155629), (15, 154656), (18, 153586), (19, 151796), (14, 149838), (20, 147657), (13, 143601), (21, 143144), (22, 139581)]
    seq length count:  (seq length, count num)
    [(100, 572), (99, 616), (98, 645), (97, 711), (96, 782), (95, 829), (94, 859), (93, 1004), (92, 1022), (91, 1117), (90, 1271), (89, 1305), (88, 1543), (87, 1572), (86, 1629), (85, 1698), (84, 1904), (83, 1976), (82, 2154), (81, 2365), (80, 2506), (79, 2846), (78, 3033), (77, 3184), (76, 3518), (75, 3630), (74, 4014), (73, 4170), (72, 4749), (71, 5061), (70, 5388), (69, 5590), (68, 6176), (67, 6689), (66, 7217), (65, 7744), (64, 8343), (63, 9033), (62, 9905), (61, 10646), (60, 11308), (59, 12336), (58, 13193), (57, 14414), (56, 15450), (55, 16969), (54, 18876), (53, 20326), (52, 20903), (51, 22590), (50, 24098), (49, 25983), (48, 28325), (47, 30461), (46, 32027), (45, 35146), (44, 37382), (43, 40306), (42, 43267), (41, 46180), (40, 50308), (39, 53441), (38, 57900), (37, 62886), (36, 66840), (35, 71266), (34, 76766), (33, 81583), (32, 87484), (31, 92126), (30, 97864), (29, 102435), (28, 107874), (27, 113869), (26, 119401), (25, 124660), (24, 130374), (23, 135714), (22, 139581), (21, 143144), (20, 147657), (19, 151796), (18, 153586), (17, 155827), (16, 155629), (15, 154656), (14, 149838), (13, 143601), (12, 138078), (11, 128739), (10, 114370), (9, 102814), (8, 79692), (7, 59132), (6, 26251), (5, 19701), (4, 8034), (3, 6680), (2, 2357), (1, 6330)]
    
    target sentence length distribution:
    most common seq length: (seq length, count num)
    [(16, 165532), (15, 164658), (14, 162805), (17, 162654), (18, 159080), (13, 156485), (19, 155026), (20, 152030), (12, 150160), (21, 146299)]
    seq length count:  (seq length, count num)
    [(100, 296), (99, 305), (98, 337), (97, 404), (96, 408), (95, 505), (94, 531), (93, 592), (92, 625), (91, 679), (90, 780), (89, 823), (88, 946), (87, 1030), (86, 1043), (85, 1231), (84, 1310), (83, 1419), (82, 1578), (81, 1669), (80, 1809), (79, 2021), (78, 2093), (77, 2262), (76, 2526), (75, 2686), (74, 2929), (73, 3126), (72, 3490), (71, 3657), (70, 4098), (69, 4449), (68, 4756), (67, 5061), (66, 5529), (65, 6028), (64, 6545), (63, 7198), (62, 7723), (61, 8621), (60, 9866), (59, 10771), (58, 11773), (57, 11776), (56, 12672), (55, 13951), (54, 15069), (53, 15959), (52, 17481), (51, 18943), (50, 20747), (49, 22558), (48, 24116), (47, 26549), (46, 28347), (45, 30953), (44, 33673), (43, 35959), (42, 38732), (41, 41909), (40, 46090), (39, 49991), (38, 53894), (37, 56454), (36, 60835), (35, 65440), (34, 70125), (33, 75182), (32, 81015), (31, 86883), (30, 91586), (29, 98251), (28, 104117), (27, 111076), (26, 118207), (25, 123028), (24, 128857), (23, 134906), (22, 140894), (21, 146299), (20, 152030), (19, 155026), (18, 159080), (17, 162654), (16, 165532), (15, 164658), (14, 162805), (13, 156485), (12, 150160), (11, 142053), (10, 134701), (9, 123547), (8, 97630), (7, 74183), (6, 33878), (5, 21733), (4, 8039), (3, 9064), (2, 2468), (1, 5062)]
    
    seq length <=50 num: 4094299
    
    验证数据: newstest2013 
    N_valid = 2883  ( 源句子-目标句子对 的数目, 过滤掉长度大于 50 的序列)
    
    source sentence length distribution:
    most common seq length: (seq length, count num)
    [(20, 121), (13, 120), (14, 115), (15, 115), (16, 115), (11, 108), (19, 106), (21, 103), (18, 103), (17, 103)]
    seq length count:  (seq length, count num)
    [(106, 1), (92, 1), (91, 1), (90, 1), (88, 1), (86, 1), (80, 2), (79, 1), (78, 1), (76, 1), (75, 1), (74, 2), (72, 1), (70, 2), (68, 1), (66, 2), (64, 3), (63, 4), (62, 6), (61, 2), (60, 4), (59, 5), (58, 4), (57, 3), (56, 3), (55, 6), (54, 9), (53, 13), (52, 8), (51, 12), (50, 10), (49, 14), (48, 17), (47, 10), (46, 14), (45, 15), (44, 10), (43, 16), (42, 13), (41, 19), (40, 33), (39, 22), (38, 24), (37, 27), (36, 40), (35, 34), (34, 45), (33, 61), (32, 45), (31, 49), (30, 53), (29, 65), (28, 58), (27, 69), (26, 79), (25, 73), (24, 81), (23, 88), (22, 98), (21, 103), (20, 121), (19, 106), (18, 103), (17, 103), (16, 115), (15, 115), (14, 115), (13, 120), (12, 96), (11, 108), (10, 98), (9, 89), (8, 89), (7, 68), (6, 67), (5, 37), (4, 24), (3, 14), (2, 18), (1, 7)]
    
    target sentence length distribution:
    most common seq length: (seq length, count num)
    [(13, 129), (15, 122), (16, 117), (11, 115), (12, 111), (20, 108), (14, 107), (10, 106), (19, 105), (18, 104)]
    seq length count:  (seq length, count num)
    [(103, 1), (98, 1), (95, 2), (92, 1), (87, 1), (85, 1), (84, 1), (83, 1), (81, 1), (80, 1), (79, 1), (77, 1), (74, 1), (72, 1), (71, 1), (69, 3), (67, 2), (66, 2), (64, 2), (63, 5), (62, 3), (61, 3), (60, 3), (59, 3), (58, 4), (57, 8), (56, 3), (55, 4), (54, 5), (53, 7), (52, 7), (51, 13), (50, 4), (49, 7), (48, 9), (47, 9), (46, 16), (45, 20), (44, 12), (43, 16), (42, 21), (41, 26), (40, 30), (39, 30), (38, 25), (37, 29), (36, 32), (35, 38), (34, 34), (33, 53), (32, 37), (31, 54), (30, 62), (29, 61), (28, 77), (27, 67), (26, 62), (25, 64), (24, 94), (23, 78), (22, 80), (21, 89), (20, 108), (19, 105), (18, 104), (17, 97), (16, 117), (15, 122), (14, 107), (13, 129), (12, 111), (11, 115), (10, 106), (9, 93), (8, 80), (7, 95), (6, 64), (5, 54), (4, 21), (3, 19), (2, 17), (1, 7)]

    
    测试数据: newstest2014
    N_test = 2737 
    
    source sentence length distribution:
    most common seq length: (seq length, count num)
    [(13, 113), (14, 112), (18, 112), (16, 101), (17, 100), (15, 100), (20, 95), (19, 94), (23, 94), (21, 92)]
    seq length count:  (seq length, count num)
    [(91, 1), (83, 1), (79, 1), (72, 2), (69, 1), (68, 2), (64, 2), (63, 2), (62, 1), (61, 2), (59, 2), (58, 9), (57, 2), (56, 4), (55, 7), (54, 2), (53, 4), (52, 7), (51, 11), (50, 14), (49, 8), (48, 12), (47, 14), (46, 15), (45, 15), (44, 26), (43, 29), (42, 21), (41, 14), (40, 29), (39, 33), (38, 35), (37, 35), (36, 44), (35, 41), (34, 46), (33, 47), (32, 53), (31, 66), (30, 63), (29, 59), (28, 73), (27, 77), (26, 58), (25, 85), (24, 86), (23, 94), (22, 92), (21, 92), (20, 95), (19, 94), (18, 112), (17, 100), (16, 101), (15, 100), (14, 112), (13, 113), (12, 82), (11, 81), (10, 73), (9, 69), (8, 52), (7, 50), (6, 36), (5, 15), (4, 7), (3, 4), (2, 2)]
    
    target sentence length distribution:
    most common seq length: (seq length, count num)
    [(19, 125), (14, 119), (15, 118), (13, 105), (17, 105), (12, 103), (10, 101), (16, 100), (20, 98), (21, 96)]
    seq length count:  (seq length, count num)
    [(75, 1), (72, 2), (70, 1), (68, 1), (64, 1), (63, 2), (60, 3), (59, 3), (58, 1), (57, 3), (56, 5), (55, 3), (54, 2), (53, 9), (52, 7), (51, 2), (50, 8), (49, 7), (48, 12), (47, 11), (46, 14), (45, 20), (44, 15), (43, 17), (42, 25), (41, 19), (40, 28), (39, 23), (38, 19), (37, 27), (36, 32), (35, 43), (34, 37), (33, 41), (32, 58), (31, 48), (30, 67), (29, 56), (28, 66), (27, 63), (26, 71), (25, 71), (24, 64), (23, 89), (22, 84), (21, 96), (20, 98), (19, 125), (18, 79), (17, 105), (16, 100), (15, 118), (14, 119), (13, 105), (12, 103), (11, 92), (10, 101), (9, 87), (8, 60), (7, 73), (6, 46), (5, 28), (4, 14), (3, 6), (2, 1)]

    
    (2) 数据预处理
    
    通过 https://nlp.stanford.edu/projects/nmt/ 介绍可知, 下载的数据集为已经预处理后的数据集,
    查看随着数据集提供的词表(vocab.50K.en), 发现并没有做大小写的转换, 并且包含 '##AT##-##AT##' 作为复合词的连接字符
    eg.
    "rich-text format" --> rich ##AT##-##AT## text format.
    
    源语言词表大小: n_vocab_source=50k
    目标语言词表大小: n_vocab_target=50k
    
    对于训练数据和验证数据, 将句子向量化为固定的长度
    源句子向量化后的长度: max_seq_length = 50
    目标句子向量化后的长度: max_seq_length = 50
    
    将源句子反向输入模型
    
    (3) 优化器参数
    
    epoch_num = 12
    batch_size = 256
    optimizer='rmsprop'
    
    (5) 训练过程
    
    在每一个 epoch 结束时都对模型进行持久化(checkpoint), 并计算在验证集上的 bleu 得分
    
    Epoch 1/10
    bleu_score:{'1-garm': 0.33720400344309615, '2-garm': 0.1725062182589224, '3-garm': 0.09731444212274992, '4-garm': 0.056584368871741786}
    15994/15994 [==============================] - 6774s 423ms/step - loss: 1.9366 - accuracy: 0.7017 - val_loss: 1.5512 - val_accuracy: 0.7598
    
    Epoch 2/10
    bleu_score:{'1-garm': 0.3954853113157417, '2-garm': 0.22273001101777612, '3-garm': 0.13619215780891972, '4-garm': 0.08605650429807646}
    15994/15994 [==============================] - 6696s 418ms/step - loss: 1.6521 - accuracy: 0.7405 - val_loss: 1.4252 - val_accuracy: 0.7793
    
    Epoch 3/10
    bleu_score:{'1-garm': 0.4098841252431386, '2-garm': 0.24047275328703602, '3-garm': 0.15204955330259137, '4-garm': 0.09908460691645932}
    15994/15994 [==============================] - 6698s 419ms/step - loss: 1.5727 - accuracy: 0.7516 - val_loss: 1.3568 - val_accuracy: 0.7870
    
    Epoch 4/10
    bleu_score:{'1-garm': 0.4270403088467624, '2-garm': 0.2561555478533417, '3-garm': 0.16441855068374778, '4-garm': 0.10822800921323789}
    15994/15994 [==============================] - 6698s 418ms/step - loss: 1.5172 - accuracy: 0.7571 - val_loss: 1.2962 - val_accuracy: 0.7929
    
    Epoch 5/10
    bleu_score:{'1-garm': 0.43400247956312415, '2-garm': 0.26275040635723784, '3-garm': 0.1701066794169419, '4-garm': 0.11309938668244064}
    15994/15994 [==============================] - 6690s 418ms/step - loss: 1.4810 - accuracy: 0.7603 - val_loss: 1.2725 - val_accuracy: 0.7947
    
    Epoch 6/10
    bleu_score:{'1-garm': 0.4344513840295986, '2-garm': 0.26561261257606256, '3-garm': 0.17418874845068721, '4-garm': 0.11715124890397059}
    15994/15994 [==============================] - 6720s 420ms/step - loss: 1.4592 - accuracy: 0.7624 - val_loss: 1.2481 - val_accuracy: 0.7968
    
    Epoch 7/10
    bleu_score:{'1-garm': 0.4338371959943409, '2-garm': 0.2680304936770957, '3-garm': 0.1768057080081019, '4-garm': 0.12011974693828713}
    15994/15994 [==============================] - 6732s 421ms/step - loss: 1.4401 - accuracy: 0.7640 - val_loss: 1.2381 - val_accuracy: 0.7977
    
    Epoch 8/10
    bleu_score:{'1-garm': 0.44176744008716473, '2-garm': 0.2733775028511106, '3-garm': 0.1811968131335106, '4-garm': 0.12333259430204008}
    15994/15994 [==============================] - 6705s 419ms/step - loss: 1.4268 - accuracy: 0.7653 - val_loss: 1.2198 - val_accuracy: 0.7992
    
    Epoch 9/10
    bleu_score:{'1-garm': 0.4491309467909158, '2-garm': 0.2797202031605641, '3-garm': 0.18624207556082573, '4-garm': 0.1274807086924977}
    15994/15994 [==============================] - 6707s 419ms/step - loss: 1.4098 - accuracy: 0.7667 - val_loss: 1.1999 - val_accuracy: 0.8006
    
    Epoch 10/10
    bleu_score:{'1-garm': 0.44730809323354026, '2-garm': 0.2808158791250601, '3-garm': 0.18784398623150456, '4-garm': 0.1292414273406333}
    15994/15994 [==============================] - 6695s 418ms/step - loss: 1.3960 - accuracy: 0.7677 - val_loss: 1.1949 - val_accuracy: 0.8017

    
    (6) 模型评价
    
    1.epoch=10 时的模型
    
    保留所有的 [UNK] 进行评价
    
    candidates:
    [0] [UNK] Andrews und Mauro [UNK] noch immer eine Freude . [END]
    [1] [UNK] Fox [UNK] und [UNK] [UNK] Andrews wollen eine getrennte Wahl . [END]
    [2] In einem Interview sagte Romney , dass er und die [UNK] einander lieben . [END]
    [3] Herman Bernanke und Barack Obamas Eltern sind zwei Jahre lang ein [UNK] von Herrn Rehn . [END]
    [4] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]
    [5] In einem Interview mit einem US ##AT##-##AT## [UNK] [UNK] [UNK] ( [UNK] ) , der am Freitag [UNK] , sagt &quot; [UNK] &quot; , wie wir es nicht tun , genau wie wir oder hoffen , dass wir &quot; [UNK] &quot; . [END]
    [6] Er und die [UNK] [UNK] sich noch immer , das 36 Jahre alte . [END]
    [7] &quot; Wir werden einander gegenseitig unterstützen und uns als Eltern zu Renminbi &quot; inspirieren . [END]
    [8] [UNK] und Schiiten sind seit 2010 geboren . [END]
    [9] [UNK] [UNK] mit [UNK] über große [UNK] [END]
    
    references:
    [0] ['[START] Orlando Bloom und Miranda Kerr lieben sich noch immer [END]']
    [1] ['[START] Schauspieler Orlando Bloom und Model Miranda Kerr wollen künftig getrennte Wege gehen . [END]']
    [2] ['[START] In einem Interview sagte Bloom jedoch , dass er und Kerr sich noch immer lieben . [END]']
    [3] ['[START] Miranda Kerr und Orlando Bloom sind Eltern des zweijährigen Flynn . [END]']
    [4] ['[START] Schauspieler Orlando Bloom hat sich zur Trennung von seiner Frau , Topmodel Miranda Kerr , geäußert . [END]']
    [5] ['[START] In einem Interview mit US ##AT##-##AT## Journalistin Katie Couric , das am Freitag ( Ortszeit ) ausgestrahlt werden sollte , sagte Bloom , &quot; das Leben verläuft manchmal nicht genau so , wie wir es planen oder erhoffen &quot; . [END]']
    [6] ['[START] Kerr und er selbst liebten sich noch immer , betonte der 36 ##AT##-##AT## Jährige . [END]']
    [7] ['[START] &quot; Wir werden uns gegenseitig unterstützen und lieben als Eltern von Flynn &quot; . [END]']
    [8] ['[START] Kerr und Bloom sind seit 2010 verheiratet , im Jahr 2011 wurde ihr Söhnchen Flynn geboren . [END]']
    [9] ['[START] Jumbo ##AT##-##AT## Hersteller streiten im Angesicht großer Bestellungen über Sitzbreite [END]']
    bleu_score:{'1-garm': 0.36025366750936405, '2-garm': 0.2014835196515774, '3-garm': 0.12195358106451964, '4-garm': 0.07680056044449779}
        
    