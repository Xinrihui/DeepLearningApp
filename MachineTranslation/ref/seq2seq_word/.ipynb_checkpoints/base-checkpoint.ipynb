{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Machine Translation using word level language model and embeddings in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "from sklearn.cross_validation import train_test_split\n",
    "# Building a english to french translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines= pd.read_table('fra.txt', names=['eng', 'fr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = lines[0:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66689</th>\n",
       "      <td>It's crawling with spiders.</td>\n",
       "      <td>Ça grouille d'araignées.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46398</th>\n",
       "      <td>Do you have any aspirin?</td>\n",
       "      <td>As-tu de l'aspirine ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50074</th>\n",
       "      <td>They're looking for you.</td>\n",
       "      <td>Ils te cherchent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29658</th>\n",
       "      <td>Can you make it safe?</td>\n",
       "      <td>Pouvez-vous vous en sortir saine et sauve ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39147</th>\n",
       "      <td>Tom folded his shirts.</td>\n",
       "      <td>Tom a plié ses chemises.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14177</th>\n",
       "      <td>Leave this to me.</td>\n",
       "      <td>Laissez.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75813</th>\n",
       "      <td>Have a cup of tea, won't you?</td>\n",
       "      <td>Vous prendrez bien une tasse de thé ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54350</th>\n",
       "      <td>I'm glad to see you here.</td>\n",
       "      <td>Je suis contente de te voir ici.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133010</th>\n",
       "      <td>The president is a down-to-earth kind of man.</td>\n",
       "      <td>Le président est plutôt quelqu'un de terre-à-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20122</th>\n",
       "      <td>You're very timid.</td>\n",
       "      <td>Vous êtes fort craintif.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  eng  \\\n",
       "66689                     It's crawling with spiders.   \n",
       "46398                        Do you have any aspirin?   \n",
       "50074                        They're looking for you.   \n",
       "29658                           Can you make it safe?   \n",
       "39147                          Tom folded his shirts.   \n",
       "14177                               Leave this to me.   \n",
       "75813                   Have a cup of tea, won't you?   \n",
       "54350                       I'm glad to see you here.   \n",
       "133010  The president is a down-to-earth kind of man.   \n",
       "20122                              You're very timid.   \n",
       "\n",
       "                                                       fr  \n",
       "66689                            Ça grouille d'araignées.  \n",
       "46398                               As-tu de l'aspirine ?  \n",
       "50074                                   Ils te cherchent.  \n",
       "29658         Pouvez-vous vous en sortir saine et sauve ?  \n",
       "39147                            Tom a plié ses chemises.  \n",
       "14177                                            Laissez.  \n",
       "75813               Vous prendrez bien une tasse de thé ?  \n",
       "54350                    Je suis contente de te voir ici.  \n",
       "133010  Le président est plutôt quelqu'un de terre-à-t...  \n",
       "20122                            Vous êtes fort craintif.  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines.eng=lines.eng.apply(lambda x: x.lower())\n",
    "lines.fr=lines.fr.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take the length as 50\n",
    "lines.eng=lines.eng.apply(lambda x: re.sub(\"'\", '', x)).apply(lambda x: re.sub(\",\", ' COMMA', x))\n",
    "lines.fr=lines.fr.apply(lambda x: re.sub(\"'\", '', x)).apply(lambda x: re.sub(\",\", ' COMMA', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = set(string.punctuation)\n",
    "lines.eng=lines.eng.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "lines.fr=lines.fr.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_digits = str.maketrans('', '', digits)\n",
    "lines.eng=lines.eng.apply(lambda x: x.translate(remove_digits))\n",
    "lines.fr=lines.fr.apply(lambda x: x.translate(remove_digits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go</td>\n",
       "      <td>START_ va  _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>run</td>\n",
       "      <td>START_ cours  _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>run</td>\n",
       "      <td>START_ courez  _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wow</td>\n",
       "      <td>START_ ça alors  _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fire</td>\n",
       "      <td>START_ au feu  _END</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    eng                     fr\n",
       "0    go        START_ va  _END\n",
       "1   run     START_ cours  _END\n",
       "2   run    START_ courez  _END\n",
       "3   wow  START_ ça alors  _END\n",
       "4  fire    START_ au feu  _END"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines.fr = lines.fr.apply(lambda x : 'START_ '+ x + ' _END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_eng_words=set()\n",
    "for eng in lines.eng:\n",
    "    for word in eng.split():\n",
    "        if word not in all_eng_words:\n",
    "            all_eng_words.add(word)\n",
    "    \n",
    "all_french_words=set()\n",
    "for fr in lines.fr:\n",
    "    for word in fr.split():\n",
    "        if word not in all_french_words:\n",
    "            all_french_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6029, 12762)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_eng_words), len(all_french_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenght_list=[]\n",
    "for l in lines.fr:\n",
    "    lenght_list.append(len(l.split(' ')))\n",
    "np.max(lenght_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenght_list=[]\n",
    "for l in lines.eng:\n",
    "    lenght_list.append(len(l.split(' ')))\n",
    "np.max(lenght_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_words = sorted(list(all_eng_words))\n",
    "target_words = sorted(list(all_french_words))\n",
    "num_encoder_tokens = len(all_eng_words)\n",
    "num_decoder_tokens = len(all_french_words)\n",
    "# del all_eng_words, all_french_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict(\n",
    "    [(word, i) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict(\n",
    "    [(word, i) for i, word in enumerate(target_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10209600000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines.fr)*16*num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros(\n",
    "    (len(lines.eng), 7),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(lines.fr), 16),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(lines.fr), 16, num_decoder_tokens),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(lines.eng, lines.fr)):\n",
    "    for t, word in enumerate(input_text.split()):\n",
    "        encoder_input_data[i, t] = input_token_index[word]\n",
    "    for t, word in enumerate(target_text.split()):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t] = target_token_index[word]\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[word]] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build keras encoder-decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None,))\n",
    "en_x=  Embedding(num_encoder_tokens, embedding_size)(encoder_inputs)\n",
    "encoder = LSTM(50, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(en_x)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "dex=  Embedding(num_decoder_tokens, embedding_size)\n",
    "\n",
    "final_dex= dex(decoder_inputs)\n",
    "\n",
    "\n",
    "decoder_lstm = LSTM(50, return_sequences=True, return_state=True)\n",
    "\n",
    "decoder_outputs, _, _ = decoder_lstm(final_dex,\n",
    "                                     initial_state=encoder_states)\n",
    "\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_20 (InputLayer)           (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_21 (InputLayer)           (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, None, 50)     301450      input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, None, 50)     638100      input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   [(None, 50), (None,  20200       embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   [(None, None, 50), ( 20200       embedding_7[0][0]                \n",
      "                                                                 lstm_6[0][1]                     \n",
      "                                                                 lstm_6[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, None, 12762)  650862      lstm_7[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,630,812\n",
      "Trainable params: 1,630,812\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47500 samples, validate on 2500 samples\n",
      "Epoch 1/20\n",
      "47500/47500 [==============================] - 90s 2ms/step - loss: 0.7957 - acc: 0.2040 - val_loss: 1.3757 - val_acc: 0.1902\n",
      "Epoch 2/20\n",
      "47500/47500 [==============================] - 90s 2ms/step - loss: 0.7902 - acc: 0.2052 - val_loss: 1.3847 - val_acc: 0.1892\n",
      "Epoch 3/20\n",
      "47500/47500 [==============================] - 90s 2ms/step - loss: 0.7852 - acc: 0.2068 - val_loss: 1.3804 - val_acc: 0.1902\n",
      "Epoch 4/20\n",
      "47500/47500 [==============================] - 90s 2ms/step - loss: 0.7801 - acc: 0.2081 - val_loss: 1.3787 - val_acc: 0.1917\n",
      "Epoch 5/20\n",
      "47500/47500 [==============================] - 90s 2ms/step - loss: 0.7751 - acc: 0.2094 - val_loss: 1.3744 - val_acc: 0.1927\n",
      "Epoch 6/20\n",
      "47500/47500 [==============================] - 91s 2ms/step - loss: 0.7694 - acc: 0.2106 - val_loss: 1.3815 - val_acc: 0.1901\n",
      "Epoch 7/20\n",
      "47500/47500 [==============================] - 90s 2ms/step - loss: 0.7620 - acc: 0.2118 - val_loss: 1.3710 - val_acc: 0.1923\n",
      "Epoch 8/20\n",
      "47500/47500 [==============================] - 90s 2ms/step - loss: 0.7529 - acc: 0.2128 - val_loss: 1.3639 - val_acc: 0.1936\n",
      "Epoch 9/20\n",
      "47500/47500 [==============================] - 90s 2ms/step - loss: 0.7446 - acc: 0.2142 - val_loss: 1.3637 - val_acc: 0.1941\n",
      "Epoch 10/20\n",
      "47500/47500 [==============================] - 90s 2ms/step - loss: 0.7386 - acc: 0.2153 - val_loss: 1.3624 - val_acc: 0.1942\n",
      "Epoch 11/20\n",
      "47500/47500 [==============================] - 90s 2ms/step - loss: 0.7339 - acc: 0.2164 - val_loss: 1.3597 - val_acc: 0.1959\n",
      "Epoch 12/20\n",
      "47500/47500 [==============================] - 90s 2ms/step - loss: 0.7302 - acc: 0.2174 - val_loss: 1.3608 - val_acc: 0.1960\n",
      "Epoch 13/20\n",
      "47500/47500 [==============================] - 90s 2ms/step - loss: 0.7268 - acc: 0.2180 - val_loss: 1.3595 - val_acc: 0.1943\n",
      "Epoch 14/20\n",
      "47500/47500 [==============================] - 90s 2ms/step - loss: 0.7235 - acc: 0.2189 - val_loss: 1.3596 - val_acc: 0.1959\n",
      "Epoch 15/20\n",
      "47500/47500 [==============================] - 90s 2ms/step - loss: 0.7204 - acc: 0.2198 - val_loss: 1.3693 - val_acc: 0.1938\n",
      "Epoch 16/20\n",
      "47500/47500 [==============================] - 90s 2ms/step - loss: 0.7175 - acc: 0.2203 - val_loss: 1.3663 - val_acc: 0.1935\n",
      "Epoch 17/20\n",
      "47500/47500 [==============================] - 90s 2ms/step - loss: 0.7146 - acc: 0.2211 - val_loss: 1.3584 - val_acc: 0.1964\n",
      "Epoch 18/20\n",
      "47500/47500 [==============================] - 90s 2ms/step - loss: 0.7117 - acc: 0.2215 - val_loss: 1.3608 - val_acc: 0.1959\n",
      "Epoch 19/20\n",
      "47500/47500 [==============================] - 90s 2ms/step - loss: 0.7086 - acc: 0.2223 - val_loss: 1.3682 - val_acc: 0.1957\n",
      "Epoch 20/20\n",
      "47500/47500 [==============================] - 91s 2ms/step - loss: 0.7058 - acc: 0.2230 - val_loss: 1.3682 - val_acc: 0.1949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f886a46af60>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=128,\n",
    "          epochs=20,\n",
    "          validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_20 (InputLayer)        (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_6 (Embedding)      (None, None, 50)          301450    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                [(None, 50), (None, 50),  20200     \n",
      "=================================================================\n",
      "Total params: 321,650\n",
      "Trainable params: 321,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create sampling model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape=(50,))\n",
    "decoder_state_input_c = Input(shape=(50,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "final_dex2= dex(decoder_inputs)\n",
    "\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(final_dex2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Function to generate sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_index['START_']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '_END' or\n",
    "           len(decoded_sentence) > 52):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at the some translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: 14077    It's almost time.\n",
      "Name: eng, dtype: object\n",
      "Decoded sentence:  il est presque temps _END\n",
      "-\n",
      "Input sentence: 20122    You're very timid.\n",
      "Name: eng, dtype: object\n",
      "Decoded sentence:  vous êtes très timide _END\n",
      "-\n",
      "Input sentence: 40035    You don't frighten me.\n",
      "Name: eng, dtype: object\n",
      "Decoded sentence:  vous ne me faites pas peur _END\n",
      "-\n",
      "Input sentence: 40064    You had better go now.\n",
      "Name: eng, dtype: object\n",
      "Decoded sentence:  tu ferais mieux dy aller maintenant _END\n",
      "-\n",
      "Input sentence: 40056    You dropped something.\n",
      "Name: eng, dtype: object\n",
      "Decoded sentence:  vous avez laissé tomber quelque chose _END\n",
      "-\n",
      "Input sentence: 40068    You have gone too far.\n",
      "Name: eng, dtype: object\n",
      "Decoded sentence:  vous êtes trop loin _END\n",
      "-\n",
      "Input sentence: 40090    You heard your mother.\n",
      "Name: eng, dtype: object\n",
      "Decoded sentence:  vous avez entendu de le mère _END\n",
      "-\n",
      "Input sentence: 40095    You live too far away.\n",
      "Name: eng, dtype: object\n",
      "Decoded sentence:  vous êtes trop loin _END\n",
      "-\n",
      "Input sentence: 40100    You look so beautiful.\n",
      "Name: eng, dtype: object\n",
      "Decoded sentence:  vous avez lair si beau _END\n",
      "-\n",
      "Input sentence: 40119    You must come with me.\n",
      "Name: eng, dtype: object\n",
      "Decoded sentence:  vous devez venir avec moi _END\n",
      "-\n",
      "Input sentence: 40131    You need to come home.\n",
      "Name: eng, dtype: object\n",
      "Decoded sentence:  il vous faut aller à la maison _END\n",
      "-\n",
      "Input sentence: 40136    You owe him the truth.\n",
      "Name: eng, dtype: object\n",
      "Decoded sentence:  tu lui dois la vérité _END\n",
      "-\n",
      "Input sentence: 40150    You should leave, Tom.\n",
      "Name: eng, dtype: object\n",
      "Decoded sentence:  tu devrais partir tom _END\n",
      "-\n",
      "Input sentence: 40153    You understand, right?\n",
      "Name: eng, dtype: object\n",
      "Decoded sentence:  vous comprends _END\n"
     ]
    }
   ],
   "source": [
    "for seq_index in [14077,20122,40035,40064, 40056, 40068, 40090, 40095, 40100, 40119, 40131, 40136, 40150, 40153]:\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', lines.eng[seq_index: seq_index + 1])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
