{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Machine Translation using word level language model and embeddings in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Building a english to french translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines= pd.read_table('fra.txt', names=['eng', 'fr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = lines[0:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11921</th>\n",
       "      <td>You are the one.</td>\n",
       "      <td>Vous êtes celui-là.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22410</th>\n",
       "      <td>It's raining again.</td>\n",
       "      <td>Il pleut à nouveau.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10161</th>\n",
       "      <td>I see something.</td>\n",
       "      <td>Je vois quelque chose.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47791</th>\n",
       "      <td>I hope you're not alone.</td>\n",
       "      <td>J'espère que tu n'es pas seul.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39570</th>\n",
       "      <td>What did Tom do wrong?</td>\n",
       "      <td>Qu'est-ce que Tom a fait de mal?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30239</th>\n",
       "      <td>He caught a big fish.</td>\n",
       "      <td>Il a attrapé un gros poisson.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21333</th>\n",
       "      <td>I enjoyed swimming.</td>\n",
       "      <td>J'adorais nager.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9175</th>\n",
       "      <td>Clean your room.</td>\n",
       "      <td>Nettoie ta chambre !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13661</th>\n",
       "      <td>I went to school.</td>\n",
       "      <td>Je suis allée à l'école.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6740</th>\n",
       "      <td>Don't fall off!</td>\n",
       "      <td>Ne tombez pas !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            eng                                fr\n",
       "11921          You are the one.               Vous êtes celui-là.\n",
       "22410       It's raining again.               Il pleut à nouveau.\n",
       "10161          I see something.            Je vois quelque chose.\n",
       "47791  I hope you're not alone.    J'espère que tu n'es pas seul.\n",
       "39570    What did Tom do wrong?  Qu'est-ce que Tom a fait de mal?\n",
       "30239     He caught a big fish.     Il a attrapé un gros poisson.\n",
       "21333       I enjoyed swimming.                  J'adorais nager.\n",
       "9175           Clean your room.              Nettoie ta chambre !\n",
       "13661         I went to school.          Je suis allée à l'école.\n",
       "6740            Don't fall off!                   Ne tombez pas !"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc sss 哦\n"
     ]
    }
   ],
   "source": [
    "str1 = 'ABc ssS 哦'\n",
    "\n",
    "print(str1.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines.eng=lines.eng.apply(lambda x: x.lower())\n",
    "lines.fr=lines.fr.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the length as 50\n",
    "lines.eng=lines.eng.apply(lambda x: re.sub(\"'\", '', x)).apply(lambda x: re.sub(\",\", ' COMMA', x))\n",
    "lines.fr=lines.fr.apply(lambda x: re.sub(\"'\", '', x)).apply(lambda x: re.sub(\",\", ' COMMA', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = set(string.punctuation)\n",
    "lines.eng=lines.eng.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "lines.fr=lines.fr.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_digits = str.maketrans('', '', digits)\n",
    "lines.eng=lines.eng.apply(lambda x: x.translate(remove_digits))\n",
    "lines.fr=lines.fr.apply(lambda x: x.translate(remove_digits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>run</td>\n",
       "      <td>cours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>run</td>\n",
       "      <td>courez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wow</td>\n",
       "      <td>ça alors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fire</td>\n",
       "      <td>au feu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    eng         fr\n",
       "0    go        va \n",
       "1   run     cours \n",
       "2   run    courez \n",
       "3   wow  ça alors \n",
       "4  fire    au feu "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines.fr = lines.fr.apply(lambda x : 'START_ '+ x + ' _END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_eng_words=set()\n",
    "for eng in lines.eng:\n",
    "    for word in eng.split():\n",
    "        if word not in all_eng_words:\n",
    "            all_eng_words.add(word)\n",
    "    \n",
    "all_french_words=set()\n",
    "for fr in lines.fr:\n",
    "    for word in fr.split():\n",
    "        if word not in all_french_words:\n",
    "            all_french_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6029, 12763)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_eng_words), len(all_french_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenght_list=[]\n",
    "for l in lines.fr:\n",
    "    lenght_list.append(len(l.split(' ')))\n",
    "np.max(lenght_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenght_list=[]\n",
    "for l in lines.eng:\n",
    "    lenght_list.append(len(l.split(' ')))\n",
    "np.max(lenght_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_words = sorted(list(all_eng_words))\n",
    "target_words = sorted(list(all_french_words))\n",
    "num_encoder_tokens = len(all_eng_words)\n",
    "num_decoder_tokens = len(all_french_words)\n",
    "# del all_eng_words, all_french_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict(\n",
    "    [(word, i) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict(\n",
    "    [(word, i) for i, word in enumerate(target_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10210400000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines.fr)*16*num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 38.0 GiB for an array with shape (50000, 16, 12763) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-7797081bffc6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m decoder_target_data = np.zeros(\n\u001b[0;32m      8\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_decoder_tokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     dtype='float32')\n\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 38.0 GiB for an array with shape (50000, 16, 12763) and data type float32"
     ]
    }
   ],
   "source": [
    "encoder_input_data = np.zeros(\n",
    "    (len(lines.eng), 7),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(lines.fr), 16),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(lines.fr), 16, num_decoder_tokens),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(lines.eng, lines.fr)):\n",
    "    for t, word in enumerate(input_text.split()):\n",
    "        encoder_input_data[i, t] = input_token_index[word]\n",
    "    for t, word in enumerate(target_text.split()):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t] = target_token_index[word]\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[word]] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build keras encoder-decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None,))\n",
    "en_x=  Embedding(num_encoder_tokens, embedding_size)(encoder_inputs)\n",
    "encoder = LSTM(50, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(en_x)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "dex=  Embedding(num_decoder_tokens, embedding_size)\n",
    "\n",
    "final_dex= dex(decoder_inputs)\n",
    "\n",
    "\n",
    "decoder_lstm = LSTM(50, return_sequences=True, return_state=True)\n",
    "\n",
    "decoder_outputs, _, _ = decoder_lstm(final_dex,\n",
    "                                     initial_state=encoder_states)\n",
    "\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_20 (InputLayer)           (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_21 (InputLayer)           (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, None, 50)     301450      input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, None, 50)     638100      input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   [(None, 50), (None,  20200       embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   [(None, None, 50), ( 20200       embedding_7[0][0]                \n",
      "                                                                 lstm_6[0][1]                     \n",
      "                                                                 lstm_6[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, None, 12762)  650862      lstm_7[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,630,812\n",
      "Trainable params: 1,630,812\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47500 samples, validate on 2500 samples\n",
      "Epoch 1/20\n",
      "47500/47500 [==============================] - 90s 2ms/step - loss: 0.7957 - acc: 0.2040 - val_loss: 1.3757 - val_acc: 0.1902\n",
      "Epoch 2/20\n",
      "47500/47500 [==============================] - 90s 2ms/step - loss: 0.7902 - acc: 0.2052 - val_loss: 1.3847 - val_acc: 0.1892\n",
      "Epoch 3/20\n",
      "47500/47500 [==============================] - 90s 2ms/step - loss: 0.7852 - acc: 0.2068 - val_loss: 1.3804 - val_acc: 0.1902\n",
      "Epoch 4/20\n",
      "47500/47500 [==============================] - 90s 2ms/step - loss: 0.7801 - acc: 0.2081 - val_loss: 1.3787 - val_acc: 0.1917\n",
      "Epoch 5/20\n",
      "47500/47500 [==============================] - 90s 2ms/step - loss: 0.7751 - acc: 0.2094 - val_loss: 1.3744 - val_acc: 0.1927\n",
      "Epoch 6/20\n",
      "47500/47500 [==============================] - 91s 2ms/step - loss: 0.7694 - acc: 0.2106 - val_loss: 1.3815 - val_acc: 0.1901\n",
      "Epoch 7/20\n",
      "47500/47500 [==============================] - 90s 2ms/step - loss: 0.7620 - acc: 0.2118 - val_loss: 1.3710 - val_acc: 0.1923\n",
      "Epoch 8/20\n",
      "47500/47500 [==============================] - 90s 2ms/step - loss: 0.7529 - acc: 0.2128 - val_loss: 1.3639 - val_acc: 0.1936\n",
      "Epoch 9/20\n",
      "47500/47500 [==============================] - 90s 2ms/step - loss: 0.7446 - acc: 0.2142 - val_loss: 1.3637 - val_acc: 0.1941\n",
      "Epoch 10/20\n",
      "47500/47500 [==============================] - 90s 2ms/step - loss: 0.7386 - acc: 0.2153 - val_loss: 1.3624 - val_acc: 0.1942\n",
      "Epoch 11/20\n",
      "47500/47500 [==============================] - 90s 2ms/step - loss: 0.7339 - acc: 0.2164 - val_loss: 1.3597 - val_acc: 0.1959\n",
      "Epoch 12/20\n",
      "47500/47500 [==============================] - 90s 2ms/step - loss: 0.7302 - acc: 0.2174 - val_loss: 1.3608 - val_acc: 0.1960\n",
      "Epoch 13/20\n",
      "47500/47500 [==============================] - 90s 2ms/step - loss: 0.7268 - acc: 0.2180 - val_loss: 1.3595 - val_acc: 0.1943\n",
      "Epoch 14/20\n",
      "47500/47500 [==============================] - 90s 2ms/step - loss: 0.7235 - acc: 0.2189 - val_loss: 1.3596 - val_acc: 0.1959\n",
      "Epoch 15/20\n",
      "47500/47500 [==============================] - 90s 2ms/step - loss: 0.7204 - acc: 0.2198 - val_loss: 1.3693 - val_acc: 0.1938\n",
      "Epoch 16/20\n",
      "47500/47500 [==============================] - 90s 2ms/step - loss: 0.7175 - acc: 0.2203 - val_loss: 1.3663 - val_acc: 0.1935\n",
      "Epoch 17/20\n",
      "47500/47500 [==============================] - 90s 2ms/step - loss: 0.7146 - acc: 0.2211 - val_loss: 1.3584 - val_acc: 0.1964\n",
      "Epoch 18/20\n",
      "47500/47500 [==============================] - 90s 2ms/step - loss: 0.7117 - acc: 0.2215 - val_loss: 1.3608 - val_acc: 0.1959\n",
      "Epoch 19/20\n",
      "47500/47500 [==============================] - 90s 2ms/step - loss: 0.7086 - acc: 0.2223 - val_loss: 1.3682 - val_acc: 0.1957\n",
      "Epoch 20/20\n",
      "47500/47500 [==============================] - 91s 2ms/step - loss: 0.7058 - acc: 0.2230 - val_loss: 1.3682 - val_acc: 0.1949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f886a46af60>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=128,\n",
    "          epochs=20,\n",
    "          validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_20 (InputLayer)        (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_6 (Embedding)      (None, None, 50)          301450    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                [(None, 50), (None, 50),  20200     \n",
      "=================================================================\n",
      "Total params: 321,650\n",
      "Trainable params: 321,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create sampling model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape=(50,))\n",
    "decoder_state_input_c = Input(shape=(50,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "final_dex2= dex(decoder_inputs)\n",
    "\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(final_dex2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Function to generate sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_index['START_']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '_END' or\n",
    "           len(decoded_sentence) > 52):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at the some translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: 14077    It's almost time.\n",
      "Name: eng, dtype: object\n",
      "Decoded sentence:  il est presque temps _END\n",
      "-\n",
      "Input sentence: 20122    You're very timid.\n",
      "Name: eng, dtype: object\n",
      "Decoded sentence:  vous êtes très timide _END\n",
      "-\n",
      "Input sentence: 40035    You don't frighten me.\n",
      "Name: eng, dtype: object\n",
      "Decoded sentence:  vous ne me faites pas peur _END\n",
      "-\n",
      "Input sentence: 40064    You had better go now.\n",
      "Name: eng, dtype: object\n",
      "Decoded sentence:  tu ferais mieux dy aller maintenant _END\n",
      "-\n",
      "Input sentence: 40056    You dropped something.\n",
      "Name: eng, dtype: object\n",
      "Decoded sentence:  vous avez laissé tomber quelque chose _END\n",
      "-\n",
      "Input sentence: 40068    You have gone too far.\n",
      "Name: eng, dtype: object\n",
      "Decoded sentence:  vous êtes trop loin _END\n",
      "-\n",
      "Input sentence: 40090    You heard your mother.\n",
      "Name: eng, dtype: object\n",
      "Decoded sentence:  vous avez entendu de le mère _END\n",
      "-\n",
      "Input sentence: 40095    You live too far away.\n",
      "Name: eng, dtype: object\n",
      "Decoded sentence:  vous êtes trop loin _END\n",
      "-\n",
      "Input sentence: 40100    You look so beautiful.\n",
      "Name: eng, dtype: object\n",
      "Decoded sentence:  vous avez lair si beau _END\n",
      "-\n",
      "Input sentence: 40119    You must come with me.\n",
      "Name: eng, dtype: object\n",
      "Decoded sentence:  vous devez venir avec moi _END\n",
      "-\n",
      "Input sentence: 40131    You need to come home.\n",
      "Name: eng, dtype: object\n",
      "Decoded sentence:  il vous faut aller à la maison _END\n",
      "-\n",
      "Input sentence: 40136    You owe him the truth.\n",
      "Name: eng, dtype: object\n",
      "Decoded sentence:  tu lui dois la vérité _END\n",
      "-\n",
      "Input sentence: 40150    You should leave, Tom.\n",
      "Name: eng, dtype: object\n",
      "Decoded sentence:  tu devrais partir tom _END\n",
      "-\n",
      "Input sentence: 40153    You understand, right?\n",
      "Name: eng, dtype: object\n",
      "Decoded sentence:  vous comprends _END\n"
     ]
    }
   ],
   "source": [
    "for seq_index in [14077,20122,40035,40064, 40056, 40068, 40090, 40095, 40100, 40119, 40131, 40136, 40150, 40153]:\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', lines.eng[seq_index: seq_index + 1])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
