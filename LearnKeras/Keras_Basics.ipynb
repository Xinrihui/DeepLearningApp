{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t2KbLji6JriC"
   },
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from tensorflow.keras.layers import Layer, LSTM, Input, Embedding, Dense, Activation, Flatten,concatenate\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tensorflow.keras.activations import *\n",
    "\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from tensorflow.data import Dataset\n",
    "\n",
    "# import keras_tuner as kt\n",
    "\n",
    "from tensorflow.keras.layers import TextVectorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Tensorflow version \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-ZvSw_owHbfR"
   },
   "source": [
    "### 下载并预览数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "colab_type": "code",
    "id": "nWuDkqLRKRd9",
    "outputId": "de57cbb8-9cf7-4871-f4fa-cdc6d32ca62b"
   },
   "outputs": [],
   "source": [
    "data = keras.datasets.fashion_mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = data.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "print( x_train.shape )\n",
    "print( x_test.shape )\n",
    "print( y_train.shape )\n",
    "print( y_test.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "NvZUwoVbNVgO",
    "outputId": "86068f24-1990-4078-a409-be8feae34eb5"
   },
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "\n",
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "id": "ND_ykm8YPINQ",
    "outputId": "9f6fac88-23ab-4892-babf-a9b878a2270d"
   },
   "outputs": [],
   "source": [
    "plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  使用 tensorflow 自带的预处理工具 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_tensor = tf.constant([[1] * 4, [2] * 4])\n",
    "print(a_tensor.get_shape())  # prints ( 2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=[[1, 1, 1, 1, 1],\n",
    "   [2, 2, 2, 2]\n",
    "]\n",
    "\n",
    "b_tensor = tf.constant(b)\n",
    "\n",
    "print(b_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_a = {}\n",
    "\n",
    "k = tf.constant('hello word').numpy()\n",
    "\n",
    "dict_a[k] = 1\n",
    "\n",
    "dict_a.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_array=tf.constant([[[1, 3], [2, 3]],\n",
    "            [[2, 1], [1, 2]],\n",
    "            [[3, 3], [3, 2]]], shape=(3, 2, 2))\n",
    "\n",
    "\n",
    "tf_array.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two tensors can be combined into one Dataset object.\n",
    "features = tf.constant([[1, 3], \n",
    "                        [2, 1], \n",
    "                        [3, 3]]) # ==> 3x2 tensor\n",
    "labels = tf.constant(['A', 'B', 'A']) # ==> 3x1 tensor\n",
    "dataset = Dataset.from_tensor_slices((features, labels))  # 把tensor 的第一个维度作为样本 id 维度, 按照此维度拼接样本\n",
    "\n",
    "list(dataset.as_numpy_iterator()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both the features and the labels tensors can be converted\n",
    "# to a Dataset object separately and combined after.\n",
    "features_dataset = Dataset.from_tensor_slices(features)\n",
    "labels_dataset = Dataset.from_tensor_slices(labels)\n",
    "dataset = Dataset.zip((features_dataset, labels_dataset))\n",
    "\n",
    "list(dataset.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tf.Tensor(\n",
      "[[1 3]\n",
      " [2 3]], shape=(2, 2), dtype=int32)\n",
      "(2,)\n",
      "[b'A' b'A']\n",
      "1\n",
      "tf.Tensor(\n",
      "[[2 1]\n",
      " [1 2]], shape=(2, 2), dtype=int32)\n",
      "(2,)\n",
      "[b'B' b'B']\n",
      "2\n",
      "tf.Tensor(\n",
      "[[3 3]\n",
      " [3 2]], shape=(2, 2), dtype=int32)\n",
      "(2,)\n",
      "[b'A' b'B']\n"
     ]
    }
   ],
   "source": [
    "# A batched feature and label set can be converted to a Dataset\n",
    "# in similar fashion.\n",
    "batched_features = tf.constant([[[1, 3], \n",
    "                                 [2, 3]],\n",
    "                                [[2, 1], \n",
    "                                 [1, 2]],\n",
    "                                [[3, 3], \n",
    "                                 [3, 2]]], shape=(3, 2, 2))\n",
    "batched_labels = tf.constant([['A', 'A'],\n",
    "                              ['B', 'B'],\n",
    "                              ['A', 'B']], shape=(3, 2))\n",
    "dataset = Dataset.from_tensor_slices((batched_features, batched_labels))\n",
    "\n",
    "dataset_batch = dataset.batch(2)\n",
    "\n",
    "for i,element in enumerate(dataset):\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    print(element[0])\n",
    "    \n",
    "#     print(element[1].shape)\n",
    "    \n",
    "    print(element[1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(<tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy=\n",
      "array([[[1, 3],\n",
      "        [2, 3]],\n",
      "\n",
      "       [[2, 1],\n",
      "        [1, 2]]])>, <tf.Tensor: shape=(2, 2), dtype=string, numpy=\n",
      "array([[b'A', b'A'],\n",
      "       [b'B', b'B']], dtype=object)>)\n",
      "1\n",
      "(<tf.Tensor: shape=(1, 2, 2), dtype=int32, numpy=\n",
      "array([[[3, 3],\n",
      "        [3, 2]]])>, <tf.Tensor: shape=(1, 2), dtype=string, numpy=array([[b'A', b'B']], dtype=object)>)\n"
     ]
    }
   ],
   "source": [
    "for i,element in enumerate(dataset_batch):\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    print(element)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_batch.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(<tf.Tensor: shape=(1, 2, 2), dtype=int32, numpy=\n",
      "array([[[1, 3],\n",
      "        [2, 3]]])>, <tf.Tensor: shape=(1, 2), dtype=string, numpy=array([[b'A', b'A']], dtype=object)>)\n",
      "1\n",
      "(<tf.Tensor: shape=(1, 2, 2), dtype=int32, numpy=\n",
      "array([[[2, 1],\n",
      "        [1, 2]]])>, <tf.Tensor: shape=(1, 2), dtype=string, numpy=array([[b'B', b'B']], dtype=object)>)\n",
      "2\n",
      "(<tf.Tensor: shape=(1, 2, 2), dtype=int32, numpy=\n",
      "array([[[3, 3],\n",
      "        [3, 2]]])>, <tf.Tensor: shape=(1, 2), dtype=string, numpy=array([[b'A', b'B']], dtype=object)>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_batch = dataset.batch(1)\n",
    "\n",
    "for i,element in enumerate(dataset_batch):\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    print(element)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(<tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy=\n",
      "array([[[1, 3],\n",
      "        [2, 3]],\n",
      "\n",
      "       [[2, 1],\n",
      "        [1, 2]]])>, <tf.Tensor: shape=(2, 2), dtype=string, numpy=\n",
      "array([[b'A', b'A'],\n",
      "       [b'B', b'B']], dtype=object)>)\n",
      "1\n",
      "(<tf.Tensor: shape=(1, 2, 2), dtype=int32, numpy=\n",
      "array([[[3, 3],\n",
      "        [3, 2]]])>, <tf.Tensor: shape=(1, 2), dtype=string, numpy=array([[b'A', b'B']], dtype=object)>)\n"
     ]
    }
   ],
   "source": [
    "dataset_batch = dataset.batch(2)\n",
    "\n",
    "for i,element in enumerate(dataset_batch):\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2 = tf.constant([[1],\n",
    "                      [2],\n",
    "                      [3]])\n",
    "\n",
    "\n",
    "for feature,label,label2 in zip(batched_features, batched_labels, label2):\n",
    "    \n",
    "    print(feature)\n",
    "    \n",
    "    print(label)\n",
    "    \n",
    "    print(label2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_in\n",
      "tf.Tensor(\n",
      "[[3 2 3 1]\n",
      " [2 1 1 2]], shape=(2, 4), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[2 3 3 3]\n",
      " [2 0 0 0]], shape=(2, 4), dtype=int32)\n",
      "target_out\n",
      "tf.Tensor(\n",
      "[[3 2 3]\n",
      " [1 1 2]], shape=(2, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[3 3 2]\n",
      " [0 0 2]], shape=(2, 3), dtype=int32)\n",
      "target_in\n",
      "tf.Tensor(\n",
      "[[1 3 2]\n",
      " [2 1 1]], shape=(2, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[3 3 3]\n",
      " [0 0 0]], shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "features = tf.constant( [\n",
    "                        [1, 3, 2, 3],\n",
    "                        [2, 1, 1, 2],\n",
    "                        [3, 3, 3, 2],\n",
    "                        [0, 0, 0, 2]\n",
    "                        ], shape=(4, 4))\n",
    "\n",
    "dataset = Dataset.from_tensor_slices(features).batch(2)\n",
    "\n",
    "source_in = dataset.map(lambda batch_text: batch_text[:, ::-1], num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "target_out = dataset.map(lambda batch_text: batch_text[:, 1:], num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "target_in = dataset.map(lambda batch_text: batch_text[:, :-1], num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "print('source_in')\n",
    "\n",
    "for ele in source_in:\n",
    "    \n",
    "    print(ele)\n",
    "\n",
    "\n",
    "print('target_out')\n",
    "\n",
    "for ele in target_out:\n",
    "    \n",
    "    print(ele)\n",
    "\n",
    "print('target_in')\n",
    "    \n",
    "for ele in target_in:\n",
    "    \n",
    "    print(ele)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "text = '&apos The English ##AT##-##AT## abc10 56 71 German 4x4 abc-10 Pro Dictionary contains over 50,813 words and 23,343 articles presented in rich ##AT##-##AT## text format articles .'\n",
    "\n",
    "# 删除单词的规则\n",
    "remove_words = r'(##AT##-##AT##|&apos|&quot)'\n",
    "\n",
    "\n",
    "# 需要删除的标点符号, 包含中文符号\n",
    "punctuation = r\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~“”？，！【】（）、。：；’‘……￥·\"\"\"\n",
    "punctuation = punctuation.replace(\"'\", \"\")  # 英语中有', 不删除 '\n",
    "punctuation = punctuation.replace(\"-\", \"\")  #\n",
    "remove_punc = r'[%s]' % re.escape(punctuation)\n",
    "\n",
    "# 删除单独的数字字符\n",
    "# eg. 'avc 10 abc-10 abc10' -> 'avc  abc-10 abc10'\n",
    "\n",
    "remove_digits = r'^(\\d+ )+|( \\d+)+ |(\\d+)$'\n",
    "\n",
    "text = tf.strings.regex_replace(text, remove_words, '')\n",
    "\n",
    "text = tf.strings.regex_replace(text, remove_punc, ' ') \n",
    "\n",
    "text = tf.strings.regex_replace(text, remove_digits, ' ')\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b' avc abc-10 10-abc abc10 aa 4x4  ', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "text = '11 999 avc 10 abc-10 10-abc abc10 50 813 aa 4x4 20'\n",
    "\n",
    "\n",
    "#  A=( \\d+) 空格+至少1个数字 为匹配字符A ,\n",
    "#  B='A+ ' 至少1个A + 空格 为匹配字符B\n",
    "# remove_digits = r'( \\d+)+ '\n",
    "\n",
    "# 考虑数字可能出现在句首\n",
    "# remove_digits = r'^(\\d+ )+|( \\d+)+ '\n",
    "\n",
    "# 考虑数字可能出现在句首和句末 \n",
    "remove_digits = r'^(\\d+ )+|( \\d+)+ |(\\d+)$'\n",
    "\n",
    "text = tf.strings.regex_replace(text, remove_digits, ' ')\n",
    "\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BRsjcOnGHjl2"
   },
   "source": [
    "## 序列（Sequential）建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Amyc6YZlo9fT"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add( Flatten(input_shape=[28,28]) )\n",
    "model.add( Dense(100, activation='relu') )\n",
    "model.add( Dense(10, activation='softmax') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "4DOLKEcTpYaI",
    "outputId": "5de9a825-f54e-4831-dd9f-da05944c958c"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h0ZEb_u_PgoP"
   },
   "outputs": [],
   "source": [
    "model = Sequential( [Flatten( input_shape=[28, 28] ),\n",
    "                     Dense( 100, activation='relu' ),\n",
    "                     Dense( 10, activation='softmax' )\n",
    "                    ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "LK6gW-GaTzTJ",
    "outputId": "af00aa82-c022-4d60-bab5-b019e97531d0"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "B4KWvGAQEnvX",
    "outputId": "5e5758e0-ffa0-4fdf-e5b8-79fecfb06ac5"
   },
   "outputs": [],
   "source": [
    "model.layers[1].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CJO98w7SEu4O"
   },
   "outputs": [],
   "source": [
    "weights, biases = model.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "colab_type": "code",
    "id": "zdEslfWsE38t",
    "outputId": "c896d775-4757-4b4c-8b05-736c989845f9"
   },
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "id": "djMrDkQ-E721",
    "outputId": "ec128471-f164-43e0-a592-8312252d0634"
   },
   "outputs": [],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "ZqrUFJs_E8hW",
    "outputId": "afe8f8b7-7845-4356-80ea-0219e0bb4c24"
   },
   "outputs": [],
   "source": [
    "print( weights.shape )\n",
    "print( biases.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JaD0S8knHthX"
   },
   "source": [
    "## 函数（Functional）建模"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 例子1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2kaO1T12Ihvi"
   },
   "outputs": [],
   "source": [
    "inputs = Input( shape=[28,28] )\n",
    "x = Flatten()( inputs )\n",
    "x = Dense(100, activation='relu')(x)\n",
    "output = Dense(10, activation='softmax')(x)\n",
    "\n",
    "basic_model = Model( inputs=[inputs], outputs=[output] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "colab_type": "code",
    "id": "QzjyDf0AJC7c",
    "outputId": "f9c43df1-f049-4b28-e9a9-9c629a44f0a2"
   },
   "outputs": [],
   "source": [
    "basic_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 例子2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def base_model(m):\n",
    "\n",
    "    # 建立模型第一层的 keras Tensor，只能是Input 或者从 别的地方传来的 tensor from keras.layer\n",
    "    X = Input(shape=(32,), name='X') # 此时 shape(None,32) ；真正训练时为 shape(m,32)\n",
    "\n",
    "    init_state = Input(shape=(32,), name='init_state')\n",
    "\n",
    "    #1.\n",
    "    # b= K.zeros((100,32))\n",
    "    # b = Input( name='input_b',tensor=K.zeros((100,32)))  #<tf.Variable 'Variable:0' shape=(100, 32) dtype=float32>\n",
    "    # 喂入模型的一个 batch的样本的数目 m 此时是未知的，因此为None ，\n",
    "    # 所以模型的第一层中，所有和 m 相关的tensor 都要使用 Input，相当于tensorflow的一个占位符，其他方法不work:\n",
    "    #\n",
    "    # 反例1:\n",
    "    # b=K.zeros((init_state.shape[0],32)) # init_state.shape[0]=None，K.zeros 的shape参数 中不能出现None\n",
    "    #\n",
    "    # 反例2:\n",
    "    # b= K.zeros((m,32)) # m 由参数传入，m=100\n",
    "    # b = Input( name='input_b',tensor=K.zeros((m,32))) # <tf.Variable 'Variable:0' shape=(100, 32) dtype=float32>\n",
    "    # 虽然成功建立的 tensor 但是和 来源于 keras.layer 的a (shape: (None,32)) 无法进行 axis=1的拼接\n",
    "    # 即报错： ValueError: A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 32), (100, 32)]\n",
    "\n",
    "    #2.\n",
    "    # 连接的所有tensor 必须来源于 keras.layer（血统纯正），否则无法生成计算图\n",
    "    # 下面两种方法都报 AttributeError: 'NoneType' object has no attribute '_inbound_nodes'\n",
    "    #M1\n",
    "    # init_state_2 = K.constant(np.zeros((1,64)), dtype='float32') \n",
    "    #M2\n",
    "    # init_state_2=K.ones((1,64))\n",
    "    \n",
    "    #M3 使用 keras.layer.Reshape 转换，但是维度不对,会自动的在全面加上一维\n",
    "    \n",
    "\n",
    "    concat = Concatenate(axis=1)([X, init_state])\n",
    "\n",
    "#     concat2= Concatenate(axis=1)([concat, b])\n",
    "#     concat2 = Concatenate(axis=0)([concat, init_state_2])\n",
    "\n",
    "    dense = Dense(1, name='dense_1')(concat)\n",
    "\n",
    "    print(dense)\n",
    "    \n",
    "    model= Model(inputs=[ X , init_state ], outputs=dense)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "M=100\n",
    "model = base_model(M)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.random.randint(0,10,size=[M,32])\n",
    "init_state=np.zeros((M,32))\n",
    "# b_train=K.zeros((M,32)) #ValueError: If your data is in the form of symbolic tensors, you should specify the `steps_per_epoch` argument (instead of the `batch_size` argument, because symbolic tensors are expected to produce batches of input data).\n",
    "\n",
    "x_train = [X, init_state]\n",
    "y_train=np.random.randint(low=0,high=2,size=[M,1])\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd')\n",
    "\n",
    "batch_size=10\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=5\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4nkFE1F7arq0"
   },
   "source": [
    "## 子类化（Subclassing）建模"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "官方教程\n",
    "\n",
    "https://keras.io/guides/making_new_layers_and_models_via_subclassing/\n",
    "\n",
    "\n",
    "可训练的权重变量(有状态)必须作为类的变量并且被 add_weight(), 如果嫌麻烦也可以直接在 init 中写 Keras layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 例子1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable([[1.], [2.]])\n",
    "x = tf.constant([[3., 4.]])\n",
    "\n",
    "tf.matmul(w, x)  # 矩阵乘法 相当于 np.dot()\n",
    "\n",
    "tf.sigmoid(w + x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Layer):\n",
    "    \n",
    "    def __init__(self, units=32):\n",
    "        super(Linear, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(\n",
    "            shape=(input_shape[-1], self.units),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True,\n",
    "        ) # 可训练的权重变量(有状态) 作为类的变量并且被 add_weight()\n",
    "        self.b = self.add_weight(\n",
    "            shape=(self.units,), initializer=\"random_normal\", trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "\n",
    "N = 2\n",
    "    \n",
    "x = tf.ones((N, 2))\n",
    "\n",
    "linear_layer = Linear(4)\n",
    "\n",
    "y = linear_layer(x)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 例子2\n",
    "\n",
    "把 Keras Layer 当做类变量, 与函数建模很类似，好处是： 不用写 输入层(Input) 和 在最后定义 model 指明输入输出层\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rI1aDQMb7cso"
   },
   "outputs": [],
   "source": [
    "class Linear(Layer):  \n",
    "  \n",
    "    def __init__( self, units=32, **kwargs ):\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "        self.dense_layer = Dense(units) \n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        x = Flatten()(inputs)\n",
    "        x = self.dense_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZHx1-mvn2IfU"
   },
   "outputs": [],
   "source": [
    "model = Linear(4)\n",
    "\n",
    "model\n",
    "\n",
    "# model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.ones((2, 2))\n",
    "linear_layer = Linear(4)\n",
    "y = linear_layer(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Layer 和 Model 的区别**\n",
    "\n",
    "\n",
    "通常，您会使用 Layer 类来定义内部计算块，并使用 Model 类来定义外部模型，即您将训练的对象。\n",
    "\n",
    "例如，在 ResNet50 模型中，您会有几个子类化 Layer 的 ResNet 块，以及一个包含整个 ResNet50 网络的 Model。\n",
    "\n",
    "Model 类具有与 Layer 相同的 API，但有如下区别：\n",
    "\n",
    "* 它会公开内置训练、评估和预测循环（model.fit()、model.evaluate()、model.predict()）。\n",
    "* 它会通过 model.layers 属性公开其内部层的列表。\n",
    "* 它会公开保存和序列化 API（save()、save_weights()…）\n",
    "\n",
    "实际上，Layer 类对应于我们在文献中所称的“层”（如“卷积层”或“循环层”）或“块”（如“ResNet 块”或“Inception 块”）。\n",
    "\n",
    "同时，Model 类对应于文献中所称的“模型”（如“深度学习模型”）或“网络”（如“深度神经网络”）。\n",
    "\n",
    "因此，如果您想知道“我应该用 Layer 类还是 Model 类？”，请问自己：我是否需要在它上面调用 fit()？我是否需要在它上面调用 save()？如果是，则使用 Model。如果不是（要么因为您的类只是更大系统中的一个块，要么因为您正在自己编写训练和保存代码），则使用 Layer。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 例子3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   By XRH in 2019.12.28\n",
    "# 使用 keras.layer 搭建神经网络 不太灵活：\n",
    "# （1）keras.layer 提供的结构太少\n",
    "# （2）要使用 后端提供的丰富的函数 还需要使用 Lambda层进行包装，较繁琐\n",
    "# 因此，我们 使用 后端的函数来 定义属于自己的层\n",
    "\n",
    "\n",
    "class ConcatDense(Layer):\n",
    "\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(ConcatDense, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        # 为该层创建一个可训练的权重\n",
    "        self.w = self.add_weight(name='w',\n",
    "                                      shape=(input_shape[0][1]+input_shape[1][1], self.output_dim),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        \n",
    "        self.b = self.add_weight( name='b',\n",
    "                                    shape=(self.output_dim,),\n",
    "                                        initializer='zeros',\n",
    "                                        trainable=False)\n",
    "        \n",
    "        self.input_shapes=input_shape\n",
    "        \n",
    "        super(ConcatDense, self).build(input_shape)  # 一定要在最后调用它\n",
    "\n",
    "    def call(self, inputs):\n",
    "        assert isinstance(inputs, list)\n",
    "        \n",
    "        print('input_shapes:', self.input_shapes)\n",
    "        \n",
    "        X, init_state = inputs # X shape: (None,32) , init_state shape: (None,32)\n",
    "        \n",
    "        print(X)\n",
    "        print(init_state)\n",
    "        \n",
    "        concat=K.concatenate([X,init_state],axis=1) # shape(None, 64)\n",
    "        print(concat) \n",
    "        \n",
    "        z = K.dot(concat, self.w) + self.b\n",
    "        # concat shape (None, 64), self.w shape(64, 10) -> shape (None, 10)\n",
    "        print(z)\n",
    "        \n",
    "        a = relu(z) # 激活函数\n",
    "        print(a)\n",
    "        \n",
    "        return a\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        shape_X, shape_init_state = input_shape\n",
    "        return (shape_X[0], self.output_dim)\n",
    "\n",
    "\n",
    "    \n",
    "def test_model():\n",
    "\n",
    "    # 建立模型第一层的 keras Tensor，只能是Input 或者从 别的地方传来的 tensor from keras.layer\n",
    "    X = Input(shape=(32,), name='X') # 此时 shape(None,32) ；真正训练时为 shape(m,32)\n",
    "\n",
    "    init_state = Input(shape=(32,), name='init_state')\n",
    "\n",
    "    layer1 = ConcatDense(10, name='layer1')([ X , init_state] )\n",
    "    \n",
    "    layer2 = Dense(1, name='layer2')(layer1)\n",
    "    \n",
    "    model= Model(inputs=[ X , init_state ], outputs=layer2)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = test_model()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N=10 # 10 个样本\n",
    "\n",
    "X=np.random.randint(0,10,size=[N,32])\n",
    "init_state=np.zeros((N,32))\n",
    "\n",
    "x_train = [X, init_state]\n",
    "y_train=np.random.randint(low=0,high=2,size=[N,1]) # 取值范围 [0, 2)\n",
    "\n",
    "# y_train\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd')\n",
    "\n",
    "batch_size=10\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=5\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型调试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor 的直接计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tensoflow 1.x \n",
    "\n",
    "采用静态图的方法，需要 使用会话来 run 计算图，其才会执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf1\n",
    "import numpy as np \n",
    "\n",
    "tf1.disable_v2_behavior()\n",
    " \n",
    " \n",
    "a=np.array(\n",
    "[[1,2,3,4,5],\n",
    "[1,2,3,4,5],\n",
    "[1,2,3,4,5]]    \n",
    ")\n",
    "# a=np.array([[2.29982214e-10,1.05035841e-03,1.04089566e-04,9.98845458e-01,\n",
    "#   5.10124494e-08,5.03688757e-10,2.52189380e-10,1.18713073e-09,\n",
    "#   2.30988277e-08,2.21948682e-08,1.48340121e-07]])\n",
    "\n",
    "\n",
    "\n",
    "input = tf1.constant(a)\n",
    "k = 3\n",
    "output = tf1.nn.top_k(input, k).indices\n",
    "\n",
    "\n",
    "# one_hot=one_hot_tensor(output,11)\n",
    "# one_hot=one_hot[0]\n",
    "# # one_hot[0].shape\n",
    "# one_hot=K.reshape(one_hot,(1,one_hot.shape[0],one_hot.shape[1]))\n",
    "# # one_hot.shape\n",
    "# one_hot_permute=K.permute_dimensions(one_hot,(1,0,2))\n",
    "# one_hot_permute.shape\n",
    "\n",
    "with tf1.Session() as sess:\n",
    "    \n",
    "    print(sess.run(input))\n",
    "    print(sess.run(output))\n",
    "#     print(sess.run(one_hot))\n",
    "#     print(sess.run(one_hot_permute))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tensorflow 2.X\n",
    "\n",
    "TensorFlow的Eager模式，也可以看做是动态图模型。该模型下不需要先构造图，然后再使用Session.run()，而是可以得到即时的反馈。这样在研究和开发时会更加符合直觉。\n",
    "\n",
    "https://zhuanlan.zhihu.com/p/47201474"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "#检查是否开启 eager 模式, 在使用了tensorflow.compat.v1 后就会将 eager 模式退出\n",
    "tf.executing_eagerly() \n",
    "\n",
    "tf.config.experimental_run_functions_eagerly(True) # 没有起到作用\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rank_2_tensor = tf.constant([[1, 2],\n",
    "                             [3, 4],\n",
    "                             [5, 6]], dtype=tf.float16)\n",
    "print(rank_2_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = tf.constant([[10,10],\n",
    "                 [11.,1.]])\n",
    "\n",
    "x = tf.constant([[1.,0.],\n",
    "                 [0.,1.]])\n",
    "\n",
    "b = tf.Variable(12.)\n",
    "\n",
    "c = np.ones((2))\n",
    "\n",
    "y = tf.matmul(a, x) + b \n",
    "\n",
    "print(y)\n",
    "\n",
    "y2 = y+c\n",
    "\n",
    "print(y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_tensor(input, k):\n",
    "    \"\"\"\n",
    "    返回张量 input, 第0个维度的 topk 个元素的标号\n",
    "\n",
    "    :param input:\n",
    "    :param k:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    return tf.nn.top_k(input,k).indices\n",
    "\n",
    "a = np.array(\n",
    "    [[1, 2, 3, 4, 5],\n",
    "     [1, 2, 2, 2, 2],\n",
    "     [1, 3, 3, 3, 6]]\n",
    ")\n",
    "k = 3\n",
    "\n",
    "# 静态图下要使用 eval 才能触发计算\n",
    "print('top_k_tensor: \\n', K.eval(top_k_tensor(a,k)))\n",
    "\n",
    "# 动态图下 直接打印即可\n",
    "print(top_k_tensor(a,k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= np.array([[1,2,3,4]])\n",
    "layer1 = Dense(1)\n",
    "\n",
    "out = layer1(a)\n",
    "out \n",
    "print(out) # 直接执行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  查看所有层(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看所有的 layer \n",
    "\n",
    "model.layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model \n",
    "\n",
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出指定层的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[2]\n",
    "\n",
    "model.layers[2].name\n",
    "\n",
    "model.get_layer('layer1')\n",
    "\n",
    "W , b = model.layers[2].get_weights()\n",
    "\n",
    "np.shape(W)\n",
    "np.shape(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出该层的所有参数\n",
    "for weight in model.get_layer('layer1').weights:\n",
    "    print(weight.name, weight.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出所有层的所有参数\n",
    "\n",
    "for i in range(len(model.layers)):\n",
    "    \n",
    "    for weight in model.layers[i].weights:\n",
    "        \n",
    "        print(weight.name, weight.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看所有层 和 所有层的输出\n",
    "\n",
    "for index in range(len(model.layers)):\n",
    "    print(model.get_layer(index=index).name, model.get_layer(index=index).output_shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型(计算图)中间层的计算结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[2].name\n",
    "\n",
    "model.layers[2].input\n",
    "\n",
    "model.layers[2].output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用 K.function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 例子1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mid_func = K.function( inputs=[ model.layers[0].input, model.layers[1].input ] ,outputs=[model.layers[2].output] )\n",
    "\n",
    "N=5 # 10 个样本\n",
    "\n",
    "X=np.random.randint(0,10,size=[N,32])\n",
    "init_state=np.zeros((N,32))\n",
    "\n",
    "x_train = [X, init_state]\n",
    "\n",
    "res = mid_func([X, init_state])\n",
    "\n",
    "np.shape(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**使用K.function()可以快速检查层的正确性**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 例子2 LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "N = 2\n",
    "max_length = 4\n",
    "n_embedding=20\n",
    "n_vocab=100\n",
    "n_a = 10\n",
    "\n",
    "\n",
    "word_embedding_layer = Embedding(n_vocab, n_embedding, input_length=max_length  , name='word_embedding')\n",
    "lstm_layer = LSTM(units=n_a, return_sequences=True, return_state=True)\n",
    "\n",
    "\n",
    "word_list = Input(shape=(max_length))  \n",
    "\n",
    "mask = (word_list != 0) # shape(N,max_length)\n",
    "\n",
    "word_embedding = word_embedding_layer(inputs=word_list)\n",
    "\n",
    "out, state_h, state_c = lstm_layer(inputs=word_embedding, mask=mask)\n",
    "    \n",
    "\n",
    "f_out = K.function(inputs=[word_list], outputs=out)\n",
    "\n",
    "f_mask = K.function(inputs=[word_list], outputs=mask)\n",
    "\n",
    "f_state_h = K.function(inputs=[word_list], outputs=state_h)\n",
    "\n",
    "f_state_c = K.function(inputs=[word_list], outputs=state_c)\n",
    "\n",
    "\n",
    "seq_data = np.ones((N, max_length))\n",
    "\n",
    "\n",
    "# seq_data =np.random.randint(n_vocab,size=(N, max_length))  \n",
    "\n",
    "res_out = f_out([seq_data])\n",
    "res_state_h = f_state_h([seq_data])\n",
    "res_state_c = f_state_c([seq_data])\n",
    "\n",
    "\n",
    "res_mask = f_mask([seq_data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(res_out)\n",
    "res_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_data\n",
    "\n",
    "np.shape(res_out)\n",
    "res_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把 LSTM 的时间步拆出来, 一步一步执行\n",
    "\n",
    "# 1.执行第1个时间步\n",
    "\n",
    "word_list_t = Input(shape=(max_length))  \n",
    "mask = (word_list_t != 0) \n",
    "word_embedding_t = word_embedding_layer(inputs=word_list_t)\n",
    "out_t, state_h_t, state_c_t = lstm_layer(inputs=word_embedding_t, mask=mask)\n",
    "\n",
    "f_out_t = K.function(inputs=[word_list_t], outputs=out_t)\n",
    "\n",
    "# 测试数据\n",
    "seq_data_0 = np.expand_dims(seq_data[:,0], axis=1)\n",
    "# np.shape(seq_data_0)\n",
    "\n",
    "# 推理\n",
    "res_out_0 = f_out_t([seq_data_0])\n",
    "res_out_0\n",
    "\n",
    "res_out[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.执行第1个时间步，给 LSTM 一个初始隐藏层状态 h0\n",
    "\n",
    "word_list_t = Input(shape=(max_length))  \n",
    "h0 = Input(shape=(n_a))\n",
    "c0 = Input(shape=(n_a))\n",
    "\n",
    "mask = (word_list_t != 0) \n",
    "word_embedding_t = word_embedding_layer(inputs=word_list_t)\n",
    "h=h0\n",
    "c=c0\n",
    "out_t, h_t, c_t = lstm_layer(inputs=word_embedding_t, mask=mask, initial_state=[h, c])\n",
    "\n",
    "f_out_t = K.function(inputs=[word_list_t, h0, c0], outputs=out_t)\n",
    "f_h_t = K.function(inputs=[word_list_t, h0, c0], outputs=h_t)\n",
    "f_c_t = K.function(inputs=[word_list_t, h0, c0], outputs=c_t)\n",
    "\n",
    "# 测试数据\n",
    "seq_data_0 = np.expand_dims(seq_data[:,0], axis=1)\n",
    "# np.shape(seq_data_0)\n",
    "\n",
    "data_h = np.ones((N, n_a))\n",
    "# data_h = np.zeros((N, n_a))\n",
    "data_c = np.zeros((N, n_a))\n",
    "\n",
    "# 推理\n",
    "res_out_0 = f_out_t([seq_data_0, data_h, data_c])\n",
    "res_out_0\n",
    "\n",
    "# res_out[:,0,:]\n",
    "\n",
    "\n",
    "res_h_t = f_h_t([seq_data_0, data_h, data_c])\n",
    "res_h_t\n",
    "\n",
    "\n",
    "res_c_t = f_c_t([seq_data_0, data_h, data_c])\n",
    "res_c_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 建立新的 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用原来的 layer 建立新的计算图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mid_model = Model( inputs=[ model.layers[0].input, model.layers[1].input ] ,outputs=[model.layers[2].output] )\n",
    "\n",
    "N=5 # 10 个样本\n",
    "\n",
    "X=np.random.randint(0,10,size=[N,32])\n",
    "init_state=np.zeros((N,32))\n",
    "\n",
    "x_train = [X, init_state]\n",
    "\n",
    "res = mid_model.predict([X, init_state])\n",
    "\n",
    "np.shape(res)\n",
    "\n",
    "# res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5R5S3CnAjA_u"
   },
   "source": [
    "## 编译和拟合模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用内置的方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zZegr331jXOY"
   },
   "outputs": [],
   "source": [
    "basic_model.compile( loss='sparse_categorical_crossentropy',\n",
    "               optimizer='adam',\n",
    "               metrics=['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 755
    },
    "colab_type": "code",
    "id": "E1iXQ1unj3po",
    "outputId": "d7e70ef0-b325-4178-c159-e01484b57ec3"
   },
   "outputs": [],
   "source": [
    "basic_model.fit( x_train, y_train, epochs=10, validation_split=0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dl2q7XZgkBGx"
   },
   "outputs": [],
   "source": [
    "class myCallback( tf.keras.callbacks.Callback ):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('acc')>0.9):\n",
    "      print(\"\\nReached 90% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "eHs6QHCxpTRl",
    "outputId": "569b8427-5bbe-45a2-b5ca-1de146b47a77"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add( Flatten(input_shape=[28,28]) )\n",
    "model.add( Dense(100, activation='relu') )\n",
    "model.add( Dense(10, activation='softmax') )\n",
    "\n",
    "model.compile( loss='sparse_categorical_crossentropy',\n",
    "               optimizer='adam',\n",
    "               metrics=['accuracy'] )\n",
    "\n",
    "model.fit( x_train, y_train, epochs=20, callbacks=[callbacks] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从头编写训练循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Prepare the training dataset.\n",
    "batch_size = 64\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = np.reshape(x_train, (-1, 784))\n",
    "x_test = np.reshape(x_test, (-1, 784))\n",
    "\n",
    "# Reserve 10,000 samples for validation.\n",
    "x_val = x_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "x_train = x_train[:-10000]\n",
    "y_train = y_train[:-10000]\n",
    "\n",
    "# Prepare the training dataset.\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "# Prepare the validation dataset.\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model\n",
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = layers.Dense(10, name=\"predictions\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an optimizer to train the model.\n",
    "optimizer = keras.optimizers.SGD(learning_rate=1e-3)\n",
    "# Instantiate a loss function.\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# Prepare the metrics.\n",
    "train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "val_acc_metric = keras.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x_batch_train, training=True)\n",
    "            loss_value = loss_fn(y_batch_train, logits)\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "        # Update training metric.\n",
    "        train_acc_metric.update_state(y_batch_train, logits)\n",
    "\n",
    "        # Log every 200 batches.\n",
    "        if step % 200 == 0:\n",
    "            print(\n",
    "                \"Training loss (for one batch) at step %d: %.4f\"\n",
    "                % (step, float(loss_value))\n",
    "            )\n",
    "            print(\"Seen so far: %d samples\" % ((step + 1) * batch_size))\n",
    "\n",
    "    # Display metrics at the end of each epoch.\n",
    "    train_acc = train_acc_metric.result()\n",
    "    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "\n",
    "    # Reset training metrics at the end of each epoch\n",
    "    train_acc_metric.reset_states()\n",
    "\n",
    "    # Run a validation loop at the end of each epoch.\n",
    "    for x_batch_val, y_batch_val in val_dataset:\n",
    "        val_logits = model(x_batch_val, training=False)\n",
    "        # Update val metrics\n",
    "        val_acc_metric.update_state(y_batch_val, val_logits)\n",
    "    val_acc = val_acc_metric.result()\n",
    "    val_acc_metric.reset_states()\n",
    "    print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
    "    print(\"Time taken: %.2fs\" % (time.time() - start_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FBtaK8QIqvgm"
   },
   "source": [
    "## 预测模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "zFmJDUHnpaHP",
    "outputId": "7467e053-8bb8-43e5-876b-25c1d02eef16"
   },
   "outputs": [],
   "source": [
    "basic_model.evaluate( x_test, y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "YLmeFPKhq9pa",
    "outputId": "95251b5d-6cb6-4ed0-c3e2-6cc0e149b3c7"
   },
   "outputs": [],
   "source": [
    "prob = model.predict( x_test[0:1] )\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "6zWKDawxtS4i",
    "outputId": "b1ec0d04-cca6-46f8-e2f9-200b7cde65ac"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.argmax(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Df1S7zmNrg6i",
    "outputId": "3461ed1f-31cc-43d0-d811-bbc7aaa75085"
   },
   "outputs": [],
   "source": [
    "print( y_test[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "id": "kRAuDP45sAuD",
    "outputId": "074d6fde-4a9f-43ce-d1f9-a95a680dbdaa"
   },
   "outputs": [],
   "source": [
    "plt.imshow(x_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vfwfZIk0r4Nn"
   },
   "outputs": [],
   "source": [
    "# 训练精度 90% 但是测试精度 87.7%，有过拟合的征兆"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a9ScZEUHvhgq"
   },
   "source": [
    "### 引进验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wdeqxXZFvlSr"
   },
   "outputs": [],
   "source": [
    "data = keras.datasets.fashion_mnist\n",
    "\n",
    "(x_train_full, y_train_full),(x_test, y_test) = data.load_data()\n",
    "\n",
    "x_valid, x_train = x_train_full[:5000] / 255.0, x_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eoWS6Qd3wuKq"
   },
   "outputs": [],
   "source": [
    "class myCallback( tf.keras.callbacks.Callback ):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('val_acc')>0.9):\n",
    "      print(\"\\nReached 90% validation accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 755
    },
    "colab_type": "code",
    "id": "OdDYrGK5wBgi",
    "outputId": "4ec8d58b-e17e-444b-b360-3de8bcc5b3e7"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add( Flatten(input_shape=[28,28]) )\n",
    "model.add( Dense(100, activation='relu') )\n",
    "model.add( Dense(10, activation='softmax') )\n",
    "\n",
    "model.compile( loss='sparse_categorical_crossentropy',\n",
    "               optimizer='adam',\n",
    "               metrics=['accuracy'] )\n",
    "\n",
    "history = model.fit( x_train,\n",
    "                     y_train,\n",
    "                     epochs=20, \n",
    "                     validation_data=(x_valid, y_valid), \n",
    "                     callbacks=[callbacks] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 755
    },
    "colab_type": "code",
    "id": "QAtj4x8mxIUM",
    "outputId": "f8ba99a6-c094-4d82-d99e-6351dfd1b320"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "data = keras.datasets.fashion_mnist\n",
    "\n",
    "(x_train_full, y_train_full),(x_test, y_test) = data.load_data()\n",
    "\n",
    "x_train_full = x_train_full.reshape(60000, 28, 28, 1)\n",
    "x_test = x_test.reshape(10000, 28, 28, 1)\n",
    "\n",
    "x_valid, x_train = x_train_full[:5000] / 255.0, x_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "\n",
    "\n",
    "model = Sequential([Conv2D(64, (3,3), activation='relu', input_shape=(28,28,1)),\n",
    "                    MaxPooling2D(2,2),\n",
    "                    Conv2D(64, (3,3), activation='relu'),\n",
    "                    MaxPooling2D(2,2),\n",
    "                    Flatten(),\n",
    "                    Dense(128, activation='relu'),\n",
    "                    Dense(10, activation='softmax') ])\n",
    "\n",
    "model.compile( loss='sparse_categorical_crossentropy',\n",
    "               optimizer='adam',\n",
    "               metrics=['accuracy'] )\n",
    "\n",
    "history = model.fit( x_train,\n",
    "                     y_train,\n",
    "                     epochs=20, \n",
    "                     validation_data=(x_valid, y_valid) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "colab_type": "code",
    "id": "O2GrT5mSA1Mu",
    "outputId": "279d5a97-0581-4f0c-f1f8-07362ab8d236"
   },
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure( figsize=(8,4), dpi=100 )\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 755
    },
    "colab_type": "code",
    "id": "qnSTby4DEY6H",
    "outputId": "630bcbce-a9d0-40f6-f969-d96607e64403"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "model = Sequential([Conv2D(64, (3,3), activation='relu', input_shape=(28,28,1)),\n",
    "                    MaxPooling2D(2,2),\n",
    "                    Conv2D(64, (3,3), activation='relu'),\n",
    "                    MaxPooling2D(2,2),\n",
    "                    Flatten(),\n",
    "                    Dropout(0.5),\n",
    "                    Dense(128, activation='relu'),\n",
    "                    Dense(10, activation='softmax') ])\n",
    "\n",
    "model.compile( loss='sparse_categorical_crossentropy',\n",
    "               optimizer='adam',\n",
    "               metrics=['accuracy'] )\n",
    "\n",
    "history = model.fit( x_train,\n",
    "                     y_train,\n",
    "                     epochs=20, \n",
    "                     validation_data=(x_valid, y_valid) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "colab_type": "code",
    "id": "mU6_w3fSIYY-",
    "outputId": "10fa9234-18b2-4229-caa2-c00174c2a664"
   },
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure( figsize=(8,4), dpi=100 )\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nAeD73T7Tn_6"
   },
   "source": [
    "## 超参数调优 Keras Tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ref**\n",
    "\n",
    "[1] https://zhuanlan.zhihu.com/p/156139224\n",
    "\n",
    "[2] https://www.tensorflow.org/tutorials/keras/keras_tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 例子1 使用序列建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "WMAB0HIlIcHz",
    "outputId": "c4973189-de2b-4f02-dbd8-5137f0225fd9"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "# from kerastuner.tuners import RandomSearch\n",
    "\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( x_train.shape )\n",
    "print( x_test.shape )\n",
    "print( y_train.shape )\n",
    "print( y_test.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add( Flatten(input_shape=[28,28]) )\n",
    "    model.add(layers.Dense(units=hp.Int('units',\n",
    "                                        min_value=32,\n",
    "                                        max_value=512,\n",
    "                                        step=32),\n",
    "                           activation='relu')) \n",
    "    model.add(layers.Dense(10, activation='softmax')) \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate',\n",
    "                      values=[1e-2, 1e-3, 1e-4])),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_accuracy', #优化目标\n",
    "    max_epochs=20, \n",
    "    directory='E:\\python package\\python-project\\DeepLearningApp\\LearnKeras\\logs',\n",
    "    project_name='image_classify')\n",
    "\n",
    "# directory 要使用绝对路径, 否则报 UnicodeDecodeError 真TM坑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "tuner.search(x_train,\n",
    "             y_train, \n",
    "             epochs=5, \n",
    "             validation_split=0.2, callbacks=[stop_early]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 例子2 使用函数建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model2(hp):\n",
    "\n",
    "    inputs = Input(shape=[28,28])\n",
    "    x = Flatten(input_shape=[28,28])(inputs)\n",
    "    x = Dense(units=hp.Int('units',\n",
    "                            min_value=50,\n",
    "                            max_value=512,\n",
    "                            step=50), activation='relu')(x)\n",
    "    output = Dense(10, activation='softmax')(x)\n",
    "\n",
    "    model = Model( inputs=[inputs], outputs=[output] )\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate',\n",
    "                      values=[1e-2, 1e-3, 1e-4])),\n",
    "        \n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    build_model2,\n",
    "    objective='val_accuracy', #优化目标\n",
    "    max_epochs=10, \n",
    "    directory='E:\\python package\\python-project\\DeepLearningApp\\LearnKeras\\logs', # directory 要使用绝对路径, 否则报 UnicodeDecodeError \n",
    "    project_name='imageclassify') # 每次运行之前, 将 imageclassify 目录删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "tuner.search(x_train,\n",
    "             y_train, \n",
    "             epochs=10, \n",
    "             validation_split=0.2, callbacks=[stop_early]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.get_best_hyperparameters()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.evaluate( x_test, y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_model.evaluate( x_test, y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 例子3"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Keras Basics",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "254.8px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
